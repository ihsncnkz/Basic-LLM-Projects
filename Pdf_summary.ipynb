{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a8fb3da1-692c-464f-9c6f-5d37ab64c8c2",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "In this project, I will create an AI asisstant for PDF summarization. Most PDFs are too long to read, and i don't have a time. Thanks to this project, I will be able to summary before going through the entire PDF and decide whether it's worth reading fully or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c1be6684-bf0b-4f3f-b645-95066e28f854",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Library\n",
    "import os\n",
    "import requests\n",
    "from dotenv import load_dotenv\n",
    "from IPython.display import Markdown, display\n",
    "from openai import OpenAI\n",
    "import fitz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c0a33482-9156-4dd1-8d87-311850e0d4f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API key looks good so far\n"
     ]
    }
   ],
   "source": [
    "# checking api key\n",
    "load_dotenv(override = True)\n",
    "api_key = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "if api_key and api_key.startswith('sk-proj-') and len(api_key)>10:\n",
    "    print(\"API key looks good so far\")\n",
    "else:\n",
    "    print(\"There might be a problem with your API key? Please visit the troubleshooting notebook!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "81bc1552-8246-4480-89cc-c3f4021c0ced",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "57ef9078-6f56-4d92-ae03-8851a2888c30",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = fitz.open(\"D:\\\\work\\\\Project\\\\LLMEngineer\\\\llm_engineering\\\\week1\\\\Article1.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5bbd210e-e6f7-4017-9149-d61deea3d12a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SYSTEMATIC REVIEW\n",
      "Open Access\n",
      "© The Author(s) 2025. Open Access  This article is licensed under a Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 \n",
      "International License, which permits any non-commercial use, sharing, distribution and reproduction in any medium or format, as long as you \n",
      "give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons licence, and indicate if you modified the \n",
      "licensed material. You do not have permission under this licence to share adapted material derived from this article or parts of it. The images or \n",
      "other third party material in this article are included in the article’s Creative Commons licence, unless indicated otherwise in a credit line to the \n",
      "material. If material is not included in the article’s Creative Commons licence and your intended use is not permitted by statutory regulation or \n",
      "exceeds the permitted use, you will need to obtain permission directly from the copyright holder. To view a copy of this licence, visit ​h​t​t​p​:​/​/​c​r​e​a​t​i​\n",
      "v​e​c​o​m​m​o​n​s​.​o​r​g​/​l​i​c​e​n​s​e​s​/​b​y​-​n​c​-​n​d​/​4​.​0​/.\n",
      "Shool et al. BMC Medical Informatics and Decision Making          (2025) 25:117 \n",
      "https://doi.org/10.1186/s12911-025-02954-4\n",
      "BMC Medical Informatics \n",
      "and Decision Making\n",
      "*Correspondence:\n",
      "Mahmood Tara\n",
      "smtara@gmail.com\n",
      "1Center for Technology and Innovation in Cardiovascular Informatics, \n",
      "Rajaie Cardiovascular Medical and Research Center, Iran University of \n",
      "Medical Sciences, Tehran, Iran\n",
      "2Rajaie Cardiovascular Medical and Research Center, Iran University of \n",
      "Medical Sciences, Tehran 1995614331, Iran\n",
      "Abstract\n",
      "Background  Large Language Models (LLMs), advanced AI tools based on transformer architectures, demonstrate \n",
      "significant potential in clinical medicine by enhancing decision support, diagnostics, and medical education. \n",
      "However, their integration into clinical workflows requires rigorous evaluation to ensure reliability, safety, and ethical \n",
      "alignment.\n",
      "Objective  This systematic review examines the evaluation parameters and methodologies applied to LLMs in clinical \n",
      "medicine, highlighting their capabilities, limitations, and application trends.\n",
      "Methods  A comprehensive review of the literature was conducted across PubMed, Scopus, Web of Science, IEEE \n",
      "Xplore, and arXiv databases, encompassing both peer-reviewed and preprint studies. Studies were screened against \n",
      "predefined inclusion and exclusion criteria to identify original research evaluating LLM performance in medical \n",
      "contexts.\n",
      "Results  The results reveal a growing interest in leveraging LLM tools in clinical settings, with 761 studies meeting \n",
      "the inclusion criteria. While general-domain LLMs, particularly ChatGPT and GPT-4, dominated evaluations (93.55%), \n",
      "medical-domain LLMs accounted for only 6.45%. Accuracy emerged as the most commonly assessed parameter \n",
      "(21.78%). Despite these advancements, the evidence base highlights certain limitations and biases across the \n",
      "included studies, emphasizing the need for careful interpretation and robust evaluation frameworks.\n",
      "Conclusions  The exponential growth in LLM research underscores their transformative potential in healthcare. \n",
      "However, addressing challenges such as ethical risks, evaluation variability, and underrepresentation of critical \n",
      "specialties will be essential. Future efforts should prioritize standardized frameworks to ensure safe, effective, and \n",
      "equitable LLM integration in clinical practice.\n",
      "Keywords  Systematic review, Large language models, LLM evaluation, Clinical medicine, Artificial intelligence in \n",
      "medicine, Deep learning in healthcare, Natural language processing\n",
      "A systematic review of large language model \n",
      "(LLM) evaluations in clinical medicine\n",
      "Sina Shool1, Sara Adimi2, Reza Saboori Amleshi1, Ehsan Bitaraf1, Reza Golpira2 and Mahmood Tara1,2*\n",
      "Page 2 of 11\n",
      "Shool et al. BMC Medical Informatics and Decision Making          (2025) 25:117 \n",
      "Background\n",
      "Background Large language models (LLMs) are advanced \n",
      "AI systems based on transformer architectures, designed \n",
      "to process and generate human language by modeling the \n",
      "probabilistic relationships between tokens in a sequence. \n",
      "Unlike traditional AI models, LLMs are pre-trained on \n",
      "massive datasets, enabling them to learn complex linguis­\n",
      "tic patterns and adapt to diverse tasks through fine-tun­\n",
      "ing or prompting. This differentiates LLMs from broader \n",
      "categories like generative AI and neural networks, which \n",
      "may encompass non-linguistic or less context-sensitive \n",
      "models [1].\n",
      "LLMs can be categorized into three primary types:\n",
      " \t•\n",
      "Encoder-only models (e.g., BERT, DeBERTa): \n",
      "Specializing in understanding text for tasks such as \n",
      "classification and sentiment analysis.\n",
      " \t•\n",
      "Decoder-only models (e.g., GPT-series, PaLM): \n",
      "Excelling in text generation and language modeling.\n",
      " \t•\n",
      "Encoder-decoder models (e.g., T5, ChatGLM): \n",
      "Designed for tasks requiring both understanding and \n",
      "generation, such as summarization and translation.\n",
      "In healthcare, LLMs have shown potential in various \n",
      "applications. For instance, ChatGPT has demonstrated \n",
      "utility in medical education by generating differential \n",
      "diagnoses and answering exam-style questions, achieving \n",
      "performance comparable to human experts in USMLE \n",
      "tests. Similarly, models like MedPaLM-2 and MedPrompt \n",
      "have been fine-tuned for specific medical tasks, ranging \n",
      "from electronic health record (EHR) analysis to generat­\n",
      "ing patient discharge summaries. Despite these advances, \n",
      "challenges such as mitigating biases, ensuring data secu­\n",
      "rity, and addressing ethical concerns remain critical for \n",
      "their broader adoption [1].\n",
      "The advent of large language models (LLMs) like Chat­\n",
      "GPT in healthcare marks a significant shift, potentially \n",
      "transforming medical practices across patient data man­\n",
      "agement, clinical research, and direct care. As digital \n",
      "technologies progress, research explores LLMs’ practical \n",
      "applications and efficacy within clinical environments. \n",
      "Notable studies, including those by Cascella et al., assess \n",
      "ChatGPT’s implementation viability, revealing its broad \n",
      "utility from enhancing patient communications to aiding \n",
      "clinical decision-making [2].\n",
      "LLMs promise substantial advancements by swiftly \n",
      "processing extensive medical literature and data, poten­\n",
      "tially revolutionizing decision support systems, person­\n",
      "alizing interactions, and supporting complex tasks like \n",
      "surgical planning as Tustumi et al. discuss [3]. Such inno­\n",
      "vations aim not only for increased efficiency but also for \n",
      "improved diagnostic accuracy and patient management. \n",
      "Yet, deploying these sophisticated tools invites critical \n",
      "discussions on their reliability, security, and ethical use, \n",
      "especially given the sensitive nature of healthcare. As \n",
      "highlighted in Nature Medicine, these technologies pres­\n",
      "ent both significant opportunities and challenges in the \n",
      "medical field [4]. Furthermore, Lahat and Klang argue \n",
      "that LLMs can help meet rising demands for special­\n",
      "ized medical services and enhance telehealth, crucial for \n",
      "addressing global health disparities [5].\n",
      "The rising importance of LLMs necessitates improved \n",
      "evaluation frameworks and interdisciplinary efforts to \n",
      "enhance their clinical integration and ensure safety and \n",
      "effectiveness​. This systematic review aims to examine the \n",
      "evaluations of LLMs within medical and clinical fields.\n",
      "Methods\n",
      "A comprehensive literature search was conducted on \n",
      "January 15, 2025, using databases such as PubMed, Sco­\n",
      "pus, Web of Science, arXiv, and IEEE Xplore. The search \n",
      "employed keywords and MeSH terms related to “evalua­\n",
      "tion,” “large language models,” “artificial intelligence chat­\n",
      "bot,” and “medical and clinical practice,” as detailed in \n",
      "Appendix Table (Table S1).\n",
      "Inclusion criteria\n",
      "The review included original research articles assess­\n",
      "ing LLMs within medical contexts, requiring that both \n",
      "abstracts and full texts were accessible. No limitations \n",
      "were imposed regarding publication date or language.\n",
      "Exclusion criteria\n",
      "Non-original articles, including reviews, letters, edito­\n",
      "rials, and conference papers, were excluded, along with \n",
      "articles lacking abstracts, those not specifying evalua­\n",
      "tion parameters, or those focusing on non-LLM models. \n",
      "Multimodal Large Language Models (MLLMs), Large \n",
      "Vision Language Models (e.g., ChatGPT 4v, LVLM, llava), \n",
      "Vision-Language Processing (VLP) models, Vision mod­\n",
      "els, Small Language Models, and general Language Mod­\n",
      "els (only Large Language Models would be included) \n",
      "were also excluded.\n",
      "Study selection\n",
      "The initial search identified multiple records, which were \n",
      "deduplicated and screened for relevance. Articles failing \n",
      "to meet inclusion criteria were systematically excluded \n",
      "per PRISMA guidelines [5]. The study selection process \n",
      "adhered to the PRISMA guidelines, and a PRISMA flow \n",
      "diagram was used to illustrate the selection process.\n",
      "Data extraction\n",
      "The remaining articles underwent detailed data extrac­\n",
      "tion, removing entries without accessible abstracts or \n",
      "full texts, missing DOIs, duplicates, and non-original \n",
      "research. The process involved answering 11 key ques­\n",
      "tions, as outlined in Table (Table 1), ensuring a thorough \n",
      "Page 3 of 11\n",
      "Shool et al. BMC Medical Informatics and Decision Making          (2025) 25:117 \n",
      "and unbiased review of evaluation of LLM performance \n",
      "in healthcare contexts.\n",
      "Titles and abstracts were independently screened by \n",
      "two reviewers to assess relevance against the inclusion \n",
      "and exclusion criteria. Full-text articles of potentially \n",
      "eligible studies were retrieved and independently evalu­\n",
      "ated by the same reviewers. Any disagreements regarding \n",
      "study eligibility were resolved through discussion. If con­\n",
      "sensus could not be reached, a third reviewer was con­\n",
      "sulted to adjudicate and reach a final decision.\n",
      "The percentages represent the proportion of studies \n",
      "within each group that evaluated a specific parameter. \n",
      "This approach ensures a clear understanding of how \n",
      "widely a parameter was assessed in relation to its group \n",
      "context.\n",
      "Human evaluation methods varied across studies, \n",
      "including expert raters, peer evaluations, and crowd­\n",
      "sourcing. However, few studies reported using standard­\n",
      "ized rubrics or guidelines, which may affect reliability \n",
      "and consistency. This variability highlights the need for \n",
      "more standardized evaluation frameworks to ensure uni­\n",
      "formity in future assessments. While this review focuses \n",
      "on identifying evaluation parameters, future studies \n",
      "could systematically categorize and analyze evaluation \n",
      "methods.\n",
      "Results\n",
      "Study selection and data extraction\n",
      "A comprehensive search across PubMed, Scopus, Web \n",
      "of Science, arXiv, and IEEE Xplore yielded 25,156 stud­\n",
      "ies, from which 2754 duplicates and 328 additional \n",
      "records were removed (Fig.  1). This resulted in 22,074 \n",
      "records being screened by title and abstract, leading to \n",
      "the exclusion of 20,198 for not meeting inclusion criteria. \n",
      "Following this, data extraction was performed on 1876 \n",
      "articles that passed the initial screening. Of these, 586 \n",
      "articles were excluded due to reasons such as inaccessible \n",
      "abstracts or full texts, lack of DOI, duplication, and non-\n",
      "original research types.\n",
      "Following a detailed full-text review, an additional \n",
      "529 articles were excluded. Ultimately, this rigorous and \n",
      "meticulous effort culminated in 761 articles from which \n",
      "data was fully extracted, as documented in Appendix \n",
      "Table (Table S2). [This appendix table represents a cor­\n",
      "nerstone of the study, containing the most comprehen­\n",
      "sive data compilation from the included articles. Due to \n",
      "its considerable length and detail—spanning over 100 \n",
      "pages—it could not be incorporated into the main manu­\n",
      "script but is made available in its entirety to ensure trans­\n",
      "parency and to highlight the exhaustive work underlying \n",
      "this research. Readers are strongly encouraged to con­\n",
      "sult Appendix Table S2 to fully appreciate the depth and \n",
      "scope of the extracted data.]\n",
      "The evaluation of publications from 2019 to 2025 \n",
      "shows a notable exponential increase in research output, \n",
      "particularly evident from 2021 onwards. In 2019, only 1 \n",
      "article was published, increasing to 3 in 2020, 6 in 2021, 7 \n",
      "in 2022, and dramatically rising to 160 in 2023. This trend \n",
      "continued into 2024, with 557 articles published, fol­\n",
      "lowed by 27 articles in early 2025, highlighting a marked \n",
      "growth in research activity over this period.\n",
      "Summary of LLMs evaluated\n",
      "The studies evaluated a total of 1,534 instances of LLMs. \n",
      "Among these, the majority were general-domain LLMs, \n",
      "accounting for 1,435 records (93.55%). In contrast, med­\n",
      "ical-domain LLMs were assessed in 99 records, making \n",
      "up 6.45% of the total.\n",
      "Among the 1,435 general-domain LLMs, the majority \n",
      "were decoder-only models, accounting for 1,340 records \n",
      "(93.4%). Encoder-decoder models were evaluated in 21 \n",
      "records (1.5%), while encoder-only models were assessed \n",
      "in 74 records (5.2%).\n",
      "In the medical-domain LLMs (99 records), decoder-\n",
      "only models dominated with 79 records (79.8%). \n",
      "Encoder-decoder models were mentioned in 4 records \n",
      "(4.0%), and encoder-only models in 14 records (14.1%). \n",
      "For 2 records (2.0%), the architecture type was not explic­\n",
      "itly detailed.\n",
      "Among the 1,340 decoder-only general-domain LLMs, \n",
      "ChatGPT was the most frequently evaluated, with 242 \n",
      "records (18.1%), followed by ChatGPT-4 (175 records, \n",
      "13.1%), GPT-4 (165 records, 12.3%), and ChatGPT-3.5 \n",
      "(139 records, 10.4%). Google PaLM 2/Bard/Gemini was \n",
      "assessed in 118 records (8.8%), while GPT-3.5 appeared \n",
      "Table 1  Key questions for data extraction\n",
      "Q1\n",
      "Based on the article provided, which medical field does \n",
      "this article pertain to?\n",
      "Q2\n",
      "Is the language of the article a non-English language? \n",
      "(yes = 1, No = 0)\n",
      "Q3\n",
      "Is an LLM or GPT mentioned in the article used for educa­\n",
      "tional purposes in medical/clinical field? (yes = 1, No = 0)\n",
      "Q4\n",
      "Is an LLM or GPT mentioned in the article used for exami­\n",
      "nation and evaluating purposes in medical/clinical field? \n",
      "(yes = 1, No = 0)\n",
      "Q5\n",
      "Is the evaluation of the LLM or GPT conducted by hu­\n",
      "mans or compared with humans? (yes = 1, No = 0)\n",
      "Q6\n",
      "What is the name of the LLM(s) or GPT(s) version evalu­\n",
      "ated in the article?\n",
      "Q7\n",
      "What is the targeted group of interest for the LLM or GPT \n",
      "mentioned in the article (e.g., doctors, nurses, students, \n",
      "patients)?\n",
      "Q8\n",
      "How are the responses of the LLM evaluated?\n",
      "Q9\n",
      "What is the gold standard against which the LLM’s \n",
      "responses are compared?\n",
      "Q10\n",
      "What tools, scales, or set of questions are used in the \n",
      "evaluation, and how many questions are there?\n",
      "Q11\n",
      "What parameters are assessed to measure the LLM’s \n",
      "responses?\n",
      "Page 4 of 11\n",
      "Shool et al. BMC Medical Informatics and Decision Making          (2025) 25:117 \n",
      "in 58 records (4.3%). Other models included Meta Llama \n",
      "2 (46 records, 3.4%), Microsoft Copilot/Bing (44 records, \n",
      "3.3%), Meta Llama 3 (41 records, 3.1%), and Anthropic \n",
      "Claude (39 records, 2.9%).\n",
      "Smaller groups of models included Mistral (27 records, \n",
      "2.0%), Qwen (2.5-72b) (20 records, 1.5%), GPT-3.5 Turbo \n",
      "(19 records, 1.4%), GPT-4o (14 records, 1.0%), ChatGPT-\n",
      "4o and Mixtral (each with 11 records, 0.8%), and Llama \n",
      "Fig. 1  PRISMA flow diagram for systematic reviews which included searches of databases\n",
      " \n",
      "Page 5 of 11\n",
      "Shool et al. BMC Medical Informatics and Decision Making          (2025) 25:117 \n",
      "(10 records, 0.7%). Models such as Baichuan (9 records, \n",
      "0.7%), Perplexity AI (8 records, 0.6%), GPT models, \n",
      "Vicuna, PMC-LLaMA, and Gemma (each with 7 records, \n",
      "0.5%) followed.\n",
      "A variety of models were evaluated in fewer than six \n",
      "records, such as GPT-4 Turbo, InternLM, ChatGPT (cus­\n",
      "tomized), GPT-4o mini, and GPT-2, all with five records \n",
      "(0.4%). Models like GPT-3, ChatGPT3.5-turbo, ERNIE \n",
      "Bot, and ChatGPT-3 were each assessed in four records \n",
      "(0.3%). Numerous other models, including Yi-C, OpenAI \n",
      "o1-mini, ChatGPT+, and WizardLM, were evaluated in \n",
      "three records (0.2%).\n",
      "The remaining models, including OpenAI o1-preview, \n",
      "Falcon, InstructGPT, and others, were assessed in two \n",
      "or fewer records (0.1%), with many—such as Baize-\n",
      "Healthcare, Alpaca, and DanteLLM_instruct_7b-v0.2-\n",
      "boosted—evaluated only once.\n",
      "Among the 21 general-domain encoder-decoder LLMs, \n",
      "ChatGLM was the most frequently evaluated, appear­\n",
      "ing in 9 records (42.9%). Both Flan-T5 and GLM-4 were \n",
      "each evaluated in 4 records (19.0%), while BART was \n",
      "assessed in 3 records (14.3%). FLAN-UL2 was evaluated \n",
      "in 1 record (4.8%).\n",
      "Among the 74 encoder-only general-domain LLMs, \n",
      "BERT was the most frequently evaluated, appearing in \n",
      "34 records (45.9%), followed by RoBERTa in 9 records \n",
      "(12.2%) and BioBERT in 7 records (9.5%). SciBERT and \n",
      "ALBERT were each assessed in 3 records (4.1%). AfroX­\n",
      "LMR and M-BERT were evaluated in 2 records each \n",
      "(2.7%).\n",
      "Several models were evaluated only once (1.4%), \n",
      "including AfriBERTa-large, AfroLM-active-l, Camem­\n",
      "BERT-with-Dates, KoBERT, ELECTRA, DNA-BERT, \n",
      "CH-BERT, \n",
      "AlphaBERT, \n",
      "SentenceBERT, \n",
      "DistilBERT, \n",
      "DeBERTa, ColBERT, and CliRoberta (domain-adaptive \n",
      "pre-trained LLM).\n",
      "Among the 79 decoder-only medical-domain LLMs, \n",
      "the most frequently evaluated were Meditron and Huatu­\n",
      "oGPT, each appearing in 10 records (12.7%). BioMistral \n",
      "followed with 6 records (7.6%), while BioGPT was evalu­\n",
      "ated in 5 records (6.3%). PULSE, MedAlpaca, and Ascle­\n",
      "pius were each assessed in 4 records (5.1%).\n",
      "Other models included MMed-Llama, which was eval­\n",
      "uated in 3 records (3.8%), and several models, including \n",
      "DocOA, ChatMed, BianQue, BenTsao, and BioMedLM, \n",
      "each assessed in 2 records (2.5%).\n",
      "The remaining models, such as SenseNova, Collec­\n",
      "tiveSFT-7B, Clinical Camel (70B), GutGPT, Doctor \n",
      "PuJiang (Dr. PJ), ChatDoctor, AntGLM-Med-10, MedL­\n",
      "lama2, MedGPT-7B, MedicalGPT, EyeGPT (fine-tuned \n",
      "version of Llama2), Drug-GPT, DermGPT, Aeyeconsult \n",
      "(based on GPT-4), MedLM Medium, MedPaLM, Med42 \n",
      "(based on Llama-2), HyperCLOVA X, Hermes7b_ITA \n",
      "(Nous-Hermes-llama-2-7b), EthioLLM-large, EthioLLM, \n",
      "ACS-GPT, and DrBode models, were each evaluated in 1 \n",
      "record (1.3%).\n",
      "Among the 4 encoder-decoder medical-domain LLMs, \n",
      "all were evaluated in a single record (25.0% each). These \n",
      "included MOPH (a Chinese-specific ophthalmic LLM), \n",
      "BiomedNLP, CLINGEN (a knowledge-infused LLM \n",
      "model), and Clinical-T5-Large.\n",
      "Among the 14 encoder-only medical-domain LLMs, \n",
      "GatorTron and BioClinicalBERT were the most fre­\n",
      "quently evaluated, each appearing in 3 records (21.4%). \n",
      "The remaining models, including MoLFormer-XL (Pro­\n",
      "tein-specific LLMs), CancerBERT, MentalBERT, Clini­\n",
      "calBERT, BioMed-RoBERTa, and BioALBERT, were each \n",
      "evaluated in 1 record (7.1%).\n",
      "Among the medical-domain LLMs with architecture \n",
      "not explicitly detailed, two models were evaluated, each \n",
      "appearing in 1 record (50.0%). These included LICT \n",
      "(Large language model-based Identifier for Cell Types) \n",
      "and ClinicLLM (an LLM trained on [HOSPITAL]’s clini­\n",
      "cal notes).\n",
      "Major specialties evaluated\n",
      "In total, the studies analyzed 781 records, providing a \n",
      "comprehensive overview of the distribution of medical \n",
      "specialties in this research. Surgery was the most fre­\n",
      "quently evaluated specialty, accounting for 220 records \n",
      "(28.2%). Within surgery, ophthalmology was the most \n",
      "common subspecialty, with 55 records (25.0%), followed \n",
      "by orthopedics with 44 records (20.0%), and urology and \n",
      "otolaryngology each with 31 records (14.1%). Plastic sur­\n",
      "gery accounted for 20 records (9.1%), while general sur­\n",
      "gery was represented in 12 records (5.5%). Less common \n",
      "subspecialties included obstetrics and gynecology with 6 \n",
      "records (2.7%), neurosurgery and bariatric surgery with 5 \n",
      "records each (2.3%), hand surgery with 3 records (1.4%), \n",
      "vascular, laparoscopic, and spine surgery each with 2 \n",
      "records (0.9%), and trauma and thoracic surgery each \n",
      "with 1 record (0.5%).\n",
      "Internal medicine was the second most frequently eval­\n",
      "uated specialty, with 119 records (15.2%). Within internal \n",
      "medicine, oncology was the predominant subspecialty, \n",
      "accounting for 56 records (47.1%), followed by endocri­\n",
      "nology with 22 records (18.5%), gastroenterology and \n",
      "hepatology with 18 records (15.1%), rheumatology with 8 \n",
      "records (6.7%), nephrology with 6 records (5.0%), hema­\n",
      "tology with 5 records (4.2%), pulmonology with 3 records \n",
      "(2.5%), and general internal medicine with 1 record \n",
      "(0.8%).\n",
      "Medical informatics was the third most commonly \n",
      "evaluated specialty, with 112 records (14.3%), followed \n",
      "by radiology with 64 records (8.2%) and general medicine \n",
      "with 53 records (6.8%). Medical education was assessed \n",
      "in 52 records (6.7%), while neurology was evaluated in 40 \n",
      "records (5.1%), and psychiatry in 30 records (3.8%).\n",
      "Page 6 of 11\n",
      "Shool et al. BMC Medical Informatics and Decision Making          (2025) 25:117 \n",
      "Emergency medicine was represented in 21 records \n",
      "(2.7%), cardiology in 15 records (1.9%), dermatology in \n",
      "11 records (1.4%), and pediatrics in 10 records (1.3%). \n",
      "Pathology accounted for 7 records (0.9%), radiation \n",
      "oncology for 5 records (0.6%), and infectious diseases and \n",
      "anesthesiology each for 4 records (0.5%). Nuclear medi­\n",
      "cine and geriatrics each accounted for 3 records (0.4%), \n",
      "and family medicine and sports medicine each for 2 \n",
      "records (0.3%). Finally, chronic diseases, patient educa­\n",
      "tion, physical medicine and rehabilitation (physiatry), \n",
      "and sleep medicine were each evaluated in 1 record \n",
      "(0.1%).\n",
      "Target audience for LLMs evaluation\n",
      "The Target audience for LLMs evaluation includes a \n",
      "total of 976 instances, distributed across various tar­\n",
      "geted groups of interest. Doctors constitute the largest \n",
      "group, with 306 instances (31.4%), followed by patients, \n",
      "accounting for 260 instances (26.6%). Medical and \n",
      "healthcare professionals and researchers make up sig­\n",
      "nificant portions, with 100 instances (10.2%) and 98 \n",
      "instances (10.0%), respectively.\n",
      "Students and residents together represent 103 \n",
      "instances, with students contributing 72 instances (7.4%) \n",
      "and residents 31 instances (3.2%). Smaller groups include \n",
      "healthcare providers at 19 instances (1.9%), caregiv­\n",
      "ers with 10 instances (1.0%), nurses and general people \n",
      "each with 7 instances (0.7%), and families or parents of \n",
      "patients contributing 13 instances (1.3%). Educators (6 \n",
      "instances, 0.6%) and learners (3 instances, 0.3%) are the \n",
      "least represented categories.\n",
      "Lastly, 44 instances (4.5%) fall under the “others or not \n",
      "mentioned” category, representing data that does not \n",
      "pertain to the primary groups of interest.\n",
      "Grouping and evaluation criteria for LLM studies\n",
      "The studies were categorized into various groups based \n",
      "on specific criteria. as follows:\n",
      " \t•\n",
      "Group A-e: Studies where the language assessed was \n",
      "exclusively English, as determined by the answer to \n",
      "Q2.\n",
      " \t•\n",
      "Group A-ne: Studies where the languages assessed \n",
      "included non-English languages or languages other \n",
      "than English, as determined by the answer to Q2.\n",
      " \t•\n",
      "Group B-h: Studies where evaluations were \n",
      "conducted directly by humans or compared with \n",
      "human evaluations (e.g., experts or others), as \n",
      "determined by the positive answer to Q5.\n",
      " \t•\n",
      "Group B-nh: Studies where evaluations were not \n",
      "conducted directly by humans or were not compared \n",
      "with human evaluations, as determined by the \n",
      "negative answer to Q5.\n",
      " \t•\n",
      "Group C: Studies where LLMs were explicitly used \n",
      "for educational purposes in the medical or clinical \n",
      "field, as determined by the positive answer to Q3.\n",
      " \t•\n",
      "Group D: Studies where LLMs were specifically \n",
      "used for examination and evaluation purposes in \n",
      "the medical or clinical field, as determined by the \n",
      "positive answer to Q4.\n",
      "This categorization highlights the diverse applications \n",
      "and evaluation contexts of LLMs in medical research, \n",
      "demonstrating the various ways these models are inte­\n",
      "grated and assessed within the field.\n",
      "Evaluation parameters\n",
      "A comprehensive analysis of evaluation parameters \n",
      "across the 761 studies, as summarized in Table S2 (col­\n",
      "umn Q11), revealed 2,239 instances of parameter usage. \n",
      "After filtering for parameters that appeared in more than \n",
      "1% of the total instances, 16 parameters were identi­\n",
      "fied as the most frequently evaluated. These parameters, \n",
      "recorded verbatim from the studies, reflect the diverse \n",
      "approaches used to assess large language models (LLMs) \n",
      "in various contexts, particularly in the medical and clini­\n",
      "cal fields.\n",
      "Figure 2 presents the percentage distribution of these \n",
      "parameters, both across the total dataset and within \n",
      "specific study groups, highlighting variations in focus \n",
      "depending on the application or evaluation criteria.\n",
      "1.\t Accuracy was the most commonly assessed \n",
      "parameter, appearing in 419 instances, representing \n",
      "21.78% of evaluations in Group A-e, 22.99% in Group \n",
      "A-ne, 21.64% in Group B-h, 21.84% in Group B-nh, \n",
      "20.38% in Group C, and 24.31% in Group D.\n",
      "2.\t Consistency was evaluated in 33 instances (2.19% \n",
      "in Group A-e, 2.20% in Group A-ne, 1.46% in Group \n",
      "B-h, 2.15% in Group B-nh, 2.23% in Group C, and \n",
      "3.45% in Group D).\n",
      "3.\t Performance was recorded in 34 instances, with \n",
      "notable percentages in Group A-ne (6.95%), Group \n",
      "B-h (4.68%), and Group D (5.17%), compared to \n",
      "1.95% in Group A-e, 1.99% in Group B-nh, and 2.65% \n",
      "in Group C.\n",
      "4.\t Reliability was assessed in 46 instances, with \n",
      "relatively higher percentages in Group B-nh (2.70%) \n",
      "and Group C (2.97%) compared to other groups.\n",
      "5.\t Clarity was evaluated in 35 instances but remained \n",
      "less prominent in most groups (< 1.0% in Group B-h \n",
      "and Group D), with slightly higher percentages in \n",
      "Group B-nh (2.10%) and Group C (2.44%).\n",
      "6.\t Quality was reported in 43 instances, with its \n",
      "highest percentage in Group C (3.82%) and modest \n",
      "levels in Group A-e (2.88%) and Group B-nh (2.76%).\n",
      "Page 7 of 11\n",
      "Shool et al. BMC Medical Informatics and Decision Making          (2025) 25:117 \n",
      "7.\t Readability was a major focus, evaluated in 95 \n",
      "instances, showing significant emphasis in Group \n",
      "C (6.48%) and consistent usage across Groups A-e \n",
      "(4.29%), A-ne (4.81%), and B-h (4.68%).\n",
      "8.\t Reasoning appeared in 13 instances, with notable \n",
      "percentages in Group A-ne (2.14%) and Group D \n",
      "(2.76%), while being evaluated at < 1.0% in other \n",
      "groups.\n",
      "9.\t Comprehensiveness, assessed in 47 instances, was \n",
      "most emphasized in Group C (3.29%) and Group \n",
      "A-ne (3.20%), with smaller percentages in other \n",
      "groups.\n",
      "10.\tCompleteness, appearing in 49 instances, was \n",
      "consistently evaluated across most groups, with the \n",
      "highest percentage in Group B-nh (2.81%).\n",
      "11.\tCorrectness was recorded in 34 instances, with its \n",
      "highest emphasis in Group D (3.10%) and Group C \n",
      "(2.76%).\n",
      "Fig. 2  Distribution of evaluation parameters in total and across groups\n",
      " \n",
      "Page 8 of 11\n",
      "Shool et al. BMC Medical Informatics and Decision Making          (2025) 25:117 \n",
      "12.\tSafety was assessed in 21 instances, with small \n",
      "percentages across all groups, peaking at 1.80% in \n",
      "Group C.\n",
      "13.\tAppropriateness appeared in 24 instances, with \n",
      "modest evaluation levels across groups, peaking at \n",
      "1.65% in Group B-nh.\n",
      "14.\tRelevancy, reported in 43 instances, was evaluated \n",
      "most prominently in Group B-nh (2.43%).\n",
      "15.\tSensitivity, assessed in 31 instances, showed a \n",
      "higher focus in Group B-h (2.05%) compared to \n",
      "other groups.\n",
      "16.\tSpecificity was recorded in 30 instances, with \n",
      "modest levels across all groups, peaking at 1.46% in \n",
      "Group B-h.\n",
      "Discussion\n",
      "Evaluation types\n",
      "The assessment of large language models (LLMs) in \n",
      "healthcare requires advanced evaluation methodologies \n",
      "that prioritize context-specific metrics, safety, and accu­\n",
      "racy, surpassing traditional benchmarks. These method­\n",
      "ologies must also address critical concerns such as data \n",
      "privacy, ethical implications, and risks posed by inac­\n",
      "curacies or biases. Additionally, the unique demands of \n",
      "healthcare require LLMs to interpret and generate spe­\n",
      "cialized medical content with high reliability and contex­\n",
      "tual relevance ​ [6, 7].\n",
      "This study highlights a dramatic increase in research \n",
      "interest in LLMs in healthcare, with publications surging \n",
      "from a single study in 2019 to 557 in 2024. This exponen­\n",
      "tial growth underscores the expanding capabilities and \n",
      "clinical potential of LLMs, particularly in diagnostics, \n",
      "decision support, medical education, and patient com­\n",
      "munication. However, the lack of standardized evaluation \n",
      "tools, variability in study designs, and ethical concerns \n",
      "such as data privacy and hallucination risks represent key \n",
      "barriers to effective evaluation of LLMs in clinical set­\n",
      "tings. Addressing these issues requires interdisciplinary \n",
      "efforts and the development of robust frameworks tai­\n",
      "lored to clinical contexts​ ​ [8–10].\n",
      "Barriers\n",
      "Clinical evaluations of LLMs necessitate interdisci­\n",
      "plinary collaboration to meet the intricate demands \n",
      "of medical practice, requiring rigorous validation and \n",
      "optimization for diverse clinical applications. The grow­\n",
      "ing use in healthcare underscores the urgent need for \n",
      "standardized evaluation frameworks to assess their per­\n",
      "formance and safety effectively ​ [11–13]. While LLMs \n",
      "offer significant advancements, their rapid development \n",
      "raises ethical concerns, including the potential erosion \n",
      "of human expertise, reduced interpersonal interactions, \n",
      "and risks of misuse. For instance, AI-generated medi­\n",
      "cal advice could diminish the role of human empathy \n",
      "in patient care. Ensuring responsible development and \n",
      "deployment through regulatory oversight is critical to \n",
      "mitigate these risks and balance innovation with societal \n",
      "well-being.\n",
      "Frameworks\n",
      "While no single evaluation framework has been univer­\n",
      "sally adopted, several studies propose initial guidelines, \n",
      "emphasizing metrics such as transparency, explainabil­\n",
      "ity, and clinical relevance. These frameworks could serve \n",
      "as a foundation for future systematic evaluations. Our \n",
      "analysis of 761 studies provides a comprehensive over­\n",
      "view of the evaluation parameters and applications of \n",
      "LLMs in healthcare. The studies focused predominantly \n",
      "on general-domain LLMs (93.55%), with decoder-only \n",
      "architectures like ChatGPT and GPT-4 being the most \n",
      "frequently evaluated models. Medical-domain LLMs, \n",
      "accounting for 6.45% of studies, demonstrated early but \n",
      "promising specialization, with models such as Meditron \n",
      "and HuatuoGPT being the most assessed. However, the \n",
      "limited evaluation of encoder-decoder and encoder-only \n",
      "models, both in general and medical domains, reveals a \n",
      "gap in exploring alternative architectures. Its extensive \n",
      "use in clinical settings underscores its versatility and \n",
      "superior performance in diagnostics and generating dif­\n",
      "ferential diagnoses, reflecting its enhanced linguistic and \n",
      "contextual processing capabilities [14–16].\n",
      "Applications and trends\n",
      "The analysis underscores the evaluation of a wide array \n",
      "of LLMs, with around one thirds of studies focusing on \n",
      "GPT models like GPT-4, and specialized or customized \n",
      "variants, reflecting tailored explorations for specific clini­\n",
      "cal tasks. Other models, including Google Bard, Micro­\n",
      "soft Bing, and BERT variants, along with Claude, Llama, \n",
      "and PaLM2, are also reviewed, pointing to a vibrant AI \n",
      "research landscape in healthcare. Yet, the limited assess­\n",
      "ment of these models highlights the necessity for stan­\n",
      "dardized evaluation frameworks to enable effective \n",
      "comparisons ​ [17].​.\n",
      "The evaluation of LLMs in healthcare reveals sig­\n",
      "nificant variations in research focus and application, \n",
      "underscoring the critical need to align research priori­\n",
      "ties with clinical demands. Surgery emerged as the most \n",
      "frequently evaluated specialty, representing 28.2% of all \n",
      "studies, reflecting its prominent role in healthcare. How­\n",
      "ever, critical specialties such as cardiology (1.9%) and \n",
      "emergency medicine (2.7%) remain significantly under­\n",
      "represented despite their global importance. These find­\n",
      "ings highlight the necessity for future research to target \n",
      "high-burden and underserved areas to maximize the \n",
      "potential impact of LLMs in clinical practice.\n",
      "Page 9 of 11\n",
      "Shool et al. BMC Medical Informatics and Decision Making          (2025) 25:117 \n",
      "Subspecialty analysis\n",
      "The analysis of subspecialties within surgery emphasizes \n",
      "the dominance of ophthalmology (25.0%), orthopedics \n",
      "(20.0%), and urology and otolaryngology (14.1% each). \n",
      "Despite their importance, general surgery (5.5%) and \n",
      "other subspecialties, including neurosurgery and vascu­\n",
      "lar surgery, were evaluated far less frequently, highlight­\n",
      "ing potential gaps in research coverage. Similarly, internal \n",
      "medicine—a key specialty—was the second most evalu­\n",
      "ated area (15.2%), with oncology (47.1%) leading among \n",
      "its subspecialties. However, other critical areas, such as \n",
      "nephrology (5.0%) and pulmonology (2.5%), were mini­\n",
      "mally represented, signaling the need for broader evalua­\n",
      "tions within this domain. Future research should focus on \n",
      "aligning LLM evaluations with the specific clinical needs \n",
      "of diverse medical specialties to ensure their effective and \n",
      "responsible integration into healthcare practice [4, 6].\n",
      "Parameter evaluations\n",
      "A total of 2,239 parameter evaluations were identified, \n",
      "with accuracy emerging as the most frequently assessed \n",
      "metric (419 instances, 21.78%). This reflects the critical \n",
      "importance of producing precise and reliable outputs in \n",
      "clinical settings. Other frequently evaluated parameters, \n",
      "such as readability (95 instances, 4.29%) and reliabil­\n",
      "ity (46 instances, 2.53%), emphasize the need for out­\n",
      "puts that are both clear and dependable. Less commonly \n",
      "assessed parameters, including safety, bias, and appropri­\n",
      "ateness, highlight areas requiring more focused research \n",
      "to address potential risks and ethical challenges in clini­\n",
      "cal applications.\n",
      "Our grouping framework, based on language, applica­\n",
      "tion purposes, and evaluation methods, revealed distinct \n",
      "patterns in LLM usage and assessment:\n",
      "Group A-e and Group A-ne studies collectively empha­\n",
      "sized accuracy as a key evaluation parameter, with usage \n",
      "rates of 21.78% and 22.99%, respectively. This reflects the \n",
      "critical need for precise and dependable outputs, regard­\n",
      "less of whether the language focus was exclusively Eng­\n",
      "lish or included non-English languages. Group A-ne \n",
      "studies, which included non-English languages, showed \n",
      "a higher focus on performance (6.95%) and comprehen­\n",
      "siveness (3.20%), reflecting the challenges of evaluating \n",
      "multilingual capabilities.\n",
      "Group B-h, involving direct human evaluations, \n",
      "emphasized accuracy (21.64%) and correctness (1.80%), \n",
      "highlighting the role of expert validation in ensuring the \n",
      "clinical utility of LLM outputs.\n",
      "Group B-nh, which relied on automated or indi­\n",
      "rect evaluations, focused on metrics like completeness \n",
      "(2.81%) and quality (2.76%), reflecting the need for reli­\n",
      "able outputs in contexts without human oversight.\n",
      "Group \n",
      "C, \n",
      "addressing \n",
      "educational \n",
      "applications, \n",
      "placed significant emphasis on readability (6.48%) and \n",
      "comprehensiveness (3.29%), crucial for effective knowl­\n",
      "edge dissemination.\n",
      "Group D, targeting examination and evaluation pur­\n",
      "poses, highlighted accuracy (24.31%) and correctness \n",
      "(3.10%) as key metrics, underscoring the importance of \n",
      "dependable outputs in high-stakes contexts.\n",
      "These group-specific analyses provide valuable insights \n",
      "into how LLMs are assessed across diverse research con­\n",
      "texts, reflecting the tailored objectives and priorities of \n",
      "each group. Notably, the limited focus on ethical param­\n",
      "eters like safety and bias across all groups highlights a \n",
      "critical gap that must be addressed to ensure equitable \n",
      "and responsible LLM integration.\n",
      "Limitations\n",
      "The evaluation of LLMs in healthcare highlights their \n",
      "varied applications and categorization by language and \n",
      "methods. Nonetheless, several issues persist, includ­\n",
      "ing an excessive focus on accuracy, which does not ade­\n",
      "quately capture the complexity of model performance in \n",
      "clinical settings. Essential factors like safety, fairness, and \n",
      "bias are often neglected, and many studies rely on closed-\n",
      "ended tasks, failing to mirror the complexity of clinical \n",
      "decision-making which requires comprehensive, open-\n",
      "ended reasoning ​ [8, 18].\n",
      "Additionally, the categorization of studies by language \n",
      "and purpose reveals varied applications of LLMs and \n",
      "underscores a lack of standardized evaluation practices. \n",
      "This fragmentation impedes a unified understanding of \n",
      "LLMs’ capabilities across medical fields. Moreover, the \n",
      "application of LLMs in clinical settings faces challenges, \n",
      "as the lack of domain-specific training data can cause \n",
      "inaccuracies, especially in precise fields like radiology or \n",
      "genetics ​ [6, 19].\n",
      "A notable limitation of this study is the restriction of \n",
      "the search strategy to titles of published studies. This \n",
      "approach, while providing a focused scope, may have \n",
      "excluded relevant studies identifiable through abstracts. \n",
      "Future systematic reviews in this domain should consider \n",
      "expanding the search strategy to include both titles and \n",
      "abstracts to ensure a more comprehensive capture of eli­\n",
      "gible studies.\n",
      "The lack of standardized definitions for some evalua­\n",
      "tion parameters and the variability in human evaluation \n",
      "practices are recognized as limitations of this review. \n",
      "While this work identifies trends in parameter usage \n",
      "and grouping criteria, future research should explore \n",
      "standardizing these definitions and frameworks within \n",
      "specific medical specialties or model types. Some find­\n",
      "ings, such as the distribution of clinical specialties and \n",
      "target audiences, provide contextual insights but are not \n",
      "directly aligned with the primary focus on evaluation \n",
      "methods. Future reviews could streamline the analysis to \n",
      "align more closely with evaluation frameworks.\n",
      "Page 10 of 11\n",
      "Shool et al. BMC Medical Informatics and Decision Making          (2025) 25:117 \n",
      "Future directions and perspectives\n",
      "To fully realize the potential of large language models \n",
      "(LLMs) in healthcare, future efforts should prioritize sev­\n",
      "eral key areas. First, enhancing interpretability is criti­\n",
      "cal to developing transparent models that clinicians can \n",
      "trust for reliable decision support. Establishing robust \n",
      "validation frameworks tailored to the complexities of \n",
      "clinical settings is equally essential to ensure the accu­\n",
      "racy and applicability of LLM outputs. Ethical consider­\n",
      "ations, such as safeguarding data privacy, mitigating bias, \n",
      "and addressing the societal impacts of automation, must \n",
      "also be a primary focus. Additionally, the evolving roles \n",
      "of healthcare professionals require exploration, as these \n",
      "technologies may shift their responsibilities from deci­\n",
      "sion-makers to supervisors of AI-generated insights. To \n",
      "mitigate risks associated with misuse or overreliance on \n",
      "LLMs, the development of comprehensive governance \n",
      "frameworks is imperative, ensuring their deployment \n",
      "aligns with ethical and safety standards. Finally, address­\n",
      "ing barriers to adoption, including resource constraints \n",
      "and resistance to change, will require interdisciplinary \n",
      "collaboration and targeted education efforts to foster \n",
      "acceptance and successful integration into healthcare \n",
      "practices.\n",
      "Conclusions\n",
      "This systematic review underscores the expanding role of \n",
      "LLMs in clinical medicine, highlighting their potential to \n",
      "revolutionize medical diagnostics, education, and patient \n",
      "care. While their applications are diverse, critical chal­\n",
      "lenges remain, including the need for standardized evalu­\n",
      "ation frameworks, attention to ethical considerations, \n",
      "and the underrepresentation of high-priority medical \n",
      "specialties. Addressing these challenges through inter­\n",
      "disciplinary collaboration and robust governance will \n",
      "be essential for the responsible deployment of LLMs. \n",
      "Future research should focus on enhancing model inter­\n",
      "pretability, tailoring evaluations to clinical complexities, \n",
      "and addressing disparities in specialty-specific applica­\n",
      "tions. By aligning technological advancements with clini­\n",
      "cal needs, LLMs can drive significant improvements in \n",
      "healthcare outcomes.\n",
      "Abbreviations\n",
      "LLM\t\n",
      "\u0007Large Language Model\n",
      "Supplementary Information\n",
      "The online version contains supplementary material available at ​h​t​t​p​s​:​/​/​d​o​i​.​o​r​\n",
      "g​/​1​0​.​1​1​8​6​/​s​1​2​9​1​1​-​0​2​5​-​0​2​9​5​4​-​4.\n",
      "Supplementary Material 1\n",
      "Acknowledgements\n",
      "Not applicable.\n",
      "Author contributions\n",
      "SS, EB, and MT conceptualized the study, developed the methodology, \n",
      "and conducted the initial literature review. SS and RSA were responsible \n",
      "for data extraction, analysis, and synthesis of the findings. EB, SA, and RG \n",
      "contributed to the interpretation of the results and provided critical revisions \n",
      "to the manuscript. MT supervised the project, provided expert guidance on \n",
      "the clinical applications of LLMs, and contributed to the final review of the \n",
      "manuscript. All authors read and approved the final manuscript.\n",
      "Funding\n",
      "This research received no specific grant from any funding agency in the \n",
      "public, commercial, or not-for-profit sectors.\n",
      "Data availability\n",
      "All data generated or analyzed during this study are included in this published \n",
      "article and its supplementary files.\n",
      "Declarations\n",
      "Ethics approval and consent to participate\n",
      "Not applicable.\n",
      "Consent for publication\n",
      "Not applicable.\n",
      "Competing interests\n",
      "The authors declare no competing interests.\n",
      "Received: 30 September 2024 / Accepted: 26 February 2025\n",
      "References\n",
      "1.\t\n",
      "Zhou H, Liu F, Gu B, Zou X, Huang J, Wu J et al. A survey of large language \n",
      "models in medicine: progress, application, and challenge. ArXiv Preprint. \n",
      "2023;arXiv:231105112.\n",
      "2.\t\n",
      "Cascella M, Montomoli J, Bellini V, Bignami E. Evaluating the feasibility of \n",
      "ChatGPT in healthcare: an analysis of multiple clinical and research scenarios. \n",
      "J Med Syst. 2023;47(1):33.\n",
      "3.\t\n",
      "Tustumi F, Andreollo NA, Aguilar-Nascimento, JEd. Future of the language \n",
      "models in healthcare: the role of chatGPT. ABCD arquivos brasileiros de \n",
      "cirurgia digestiva (são paulo). 2023;36:e1727.\n",
      "4.\t\n",
      "Wilhelm TI, Roos J, Kaczmarczyk R. Large language models for therapy recom­\n",
      "mendations across 3 clinical specialties: comparative study. J Med Internet \n",
      "Res. 2023;25:e49324.\n",
      "5.\t\n",
      "Lahat A, Klang E. Can advanced technologies help address the global \n",
      "increase in demand for specialized medical care and improve telehealth \n",
      "services? J Telemed Telecare. 2024;30(9).\n",
      "6.\t\n",
      "Chen X, Xiang J, Lu S, Liu Y, He M, Shi D. Evaluating large language models in \n",
      "medical applications: a survey. ArXiv Preprint. 2024;arXiv:240507468.\n",
      "7.\t\n",
      "Karabacak M, Margetis K. Embracing large language models for medical \n",
      "applications: opportunities and challenges. Cureus. 2023;15(5):e39305.\n",
      "8.\t\n",
      "Nazi ZA, Peng W. Large language models in healthcare and medical domain: \n",
      "A review. ArXiv Preprint. 2023;arXiv:240106775.\n",
      "9.\t\n",
      "Ríos-Hoyo A, Shan NL, Li A, Pearson AT, Pusztai L, Howard FM. Evaluation of \n",
      "large language models as a diagnostic aid for complex medical cases. Front \n",
      "Med. 2024;11:1380148.\n",
      "10.\t Zhou H, Liu F, Gu B, Zou X, Huang J, Wu J et al. A survey of large language \n",
      "models in medicine: principles, applications, and challenges. arXiv preprint. \n",
      "2023;arXiv:231105112.\n",
      "11.\t Busch F, Hoffmann L, Rueger C, van Dijk EHC, Kader R, Ortiz-Prado E et al. \n",
      "Systematic review of large language models for patient care: current applica­\n",
      "tions and challenges. medRxiv. 2024:2024.03.04.24303733.\n",
      "12.\t Park Y-J, Pillai A, Deng J, Guo E, Gupta M, Paget M, et al. Assessing the research \n",
      "landscape and clinical utility of large language models: a scoping review. \n",
      "BMC Med Inf Decis Mak. 2024;24(1):72.\n",
      "13.\t Perlis RH, Fihn SD. Evaluating the application of large language models in \n",
      "clinical research contexts. JAMA Netw Open. 2023;6(10):e2335924–e.\n",
      "Page 11 of 11\n",
      "Shool et al. BMC Medical Informatics and Decision Making          (2025) 25:117 \n",
      "14.\t Hoppe JM, Auer MK, Strüven A, Massberg S, Stremmel C. ChatGPT with GPT-4 \n",
      "outperforms emergency department physicians in diagnostic accuracy: \n",
      "retrospective analysis. J Med Internet Res. 2024;26:e56110.\n",
      "15.\t Mackey BP, Garabet R, Maule L, Tadesse A, Cross J, Weingarten M. Evaluating \n",
      "ChatGPT-4 in medical education: an assessment of subject exam perfor­\n",
      "mance reveals limitations in clinical curriculum support for students. Discover \n",
      "Artif Intell. 2024;4(1):38.\n",
      "16.\t Ueda D, Walston SL, Matsumoto T, Deguchi R, Tatekawa H, Miki Y. Evaluating \n",
      "GPT-4-based ChatGPT’s clinical potential on the NEJM quiz. BMC Digit Health. \n",
      "2024;2(1):4.\n",
      "17.\t Alessandri-Bonetti MGR, Naegeli M, Liu HY, Egro FM. Assessing the soft tissue \n",
      "infection expertise of ChatGPT and Bard compared to IDSA recommenda­\n",
      "tions. Ann Biomed Eng. 2023.\n",
      "18.\t Liu F, Zhou H, Hua Y, Rohanian O, Clifton L, Clifton DA. Large lan­\n",
      "guage models in healthcare: A comprehensive benchmark. MedRxiv. \n",
      "2024:2024.04.24.24306315.\n",
      "19.\t García-Méndez S, de Arriba-Pérez F. Large language models and healthcare \n",
      "alliance: potential and challenges of two representative use cases. Ann \n",
      "Biomed Eng. 2024;52(8):1928–31.\n",
      "Publisher’s note\n",
      "Springer Nature remains neutral with regard to jurisdictional claims in \n",
      "published maps and institutional affiliations.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# I used the fitz library for the read article.\n",
    "text = \"\"\n",
    "for page in doc:\n",
    "    text += page.get_text()\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8f1d0491-0298-4052-b6de-72c1742300a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I prepared the system prompt for AI asisstant\n",
    "system_prompt = \"You are an AI assistant specialized in reading and summarizing long texts, such as academic articles, research papers, and reports. \\\n",
    "Your task is to read the given document carefully and generate a clear, concise, and informative summary. Focus on capturing the main points, key findings,\\\n",
    "and essential information. Do not copy text directly; instead, paraphrase in a natural and readable way.\\\n",
    "The summary should help the reader quickly understand the purpose and content of the original document and decide whether it is worth reading in full.\"\n",
    "\n",
    "# I updated the system prompt for AI asistant give Turkish language.\n",
    "\n",
    "system_prompt_v2 = \"\"\"You are an AI assistant specialized in reading and summarizing long texts such as academic articles, research papers, and reports. \\\n",
    "Your task is to read the given document carefully and generate a clear, concise, and informative summary. Focus on capturing the main points, key arguments, \\\n",
    "and important findings. Do not copy text directly; instead, paraphrase in a natural and readable way.\n",
    "\n",
    "You can produce summaries in English or Turkish depending on the user’s prompt. If the user requests it in Turkish, write the summary in Turkish. \\\n",
    "Otherwise, default to English.\n",
    "\n",
    "The summary should help the user quickly understand the content and purpose of the original document and decide whether to read it fully.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9ac592fb-592e-45a0-bb80-83dc26899118",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'You are an AI assistant specialized in reading and summarizing long texts such as academic articles, research papers, and reports. Your task is to read the given document carefully and generate a clear, concise, and informative summary. Focus on capturing the main points, key arguments, and important findings. Do not copy text directly; instead, paraphrase in a natural and readable way.\\n\\nYou can produce summaries in English or Turkish depending on the user’s prompt. If the user requests it in Turkish, write the summary in Turkish. Otherwise, default to English.\\n\\nThe summary should help the user quickly understand the content and purpose of the original document and decide whether to read it fully.'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "system_prompt_v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "53e84c65-73b5-45bd-b06d-a5ebfa774a1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I prepared the user prompt for AI asisstant\n",
    "def user_prompt_for(article_text, language):\n",
    "    user_prompt = \"\"\"Please read the following document and provide a well-structured summary. \\\n",
    "        Focus on the main ideas, important arguments, and key findings. \\\n",
    "        Your summary should be clear and concise, and written in natural language. \\\n",
    "        Avoid copying long passages from the text. \\\n",
    "        The goal is to help me quickly understand what the document is about. \"\"\"\n",
    "    user_prompt += f\"Please prepare the document with {language} language\\n\\n\"\n",
    "    user_prompt += f\"Document:\\n{article_text}\"\n",
    "    return user_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9bdc6666-8218-4139-bc9c-cc497ef72f22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please read the following document and provide a well-structured summary.         Focus on the main ideas, important arguments, and key findings.         Your summary should be clear and concise, and written in natural language.         Avoid copying long passages from the text.         The goal is to help me quickly understand what the document is about. Please prepare the document with Turkish language\n",
      "\n",
      "Document:\n",
      "SYSTEMATIC REVIEW\n",
      "Open Access\n",
      "© The Author(s) 2025. Open Access  This article is licensed under a Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 \n",
      "International License, which permits any non-commercial use, sharing, distribution and reproduction in any medium or format, as long as you \n",
      "give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons licence, and indicate if you modified the \n",
      "licensed material. You do not have permission under this licence to share adapted material derived from this article or parts of it. The images or \n",
      "other third party material in this article are included in the article’s Creative Commons licence, unless indicated otherwise in a credit line to the \n",
      "material. If material is not included in the article’s Creative Commons licence and your intended use is not permitted by statutory regulation or \n",
      "exceeds the permitted use, you will need to obtain permission directly from the copyright holder. To view a copy of this licence, visit ​h​t​t​p​:​/​/​c​r​e​a​t​i​\n",
      "v​e​c​o​m​m​o​n​s​.​o​r​g​/​l​i​c​e​n​s​e​s​/​b​y​-​n​c​-​n​d​/​4​.​0​/.\n",
      "Shool et al. BMC Medical Informatics and Decision Making          (2025) 25:117 \n",
      "https://doi.org/10.1186/s12911-025-02954-4\n",
      "BMC Medical Informatics \n",
      "and Decision Making\n",
      "*Correspondence:\n",
      "Mahmood Tara\n",
      "smtara@gmail.com\n",
      "1Center for Technology and Innovation in Cardiovascular Informatics, \n",
      "Rajaie Cardiovascular Medical and Research Center, Iran University of \n",
      "Medical Sciences, Tehran, Iran\n",
      "2Rajaie Cardiovascular Medical and Research Center, Iran University of \n",
      "Medical Sciences, Tehran 1995614331, Iran\n",
      "Abstract\n",
      "Background  Large Language Models (LLMs), advanced AI tools based on transformer architectures, demonstrate \n",
      "significant potential in clinical medicine by enhancing decision support, diagnostics, and medical education. \n",
      "However, their integration into clinical workflows requires rigorous evaluation to ensure reliability, safety, and ethical \n",
      "alignment.\n",
      "Objective  This systematic review examines the evaluation parameters and methodologies applied to LLMs in clinical \n",
      "medicine, highlighting their capabilities, limitations, and application trends.\n",
      "Methods  A comprehensive review of the literature was conducted across PubMed, Scopus, Web of Science, IEEE \n",
      "Xplore, and arXiv databases, encompassing both peer-reviewed and preprint studies. Studies were screened against \n",
      "predefined inclusion and exclusion criteria to identify original research evaluating LLM performance in medical \n",
      "contexts.\n",
      "Results  The results reveal a growing interest in leveraging LLM tools in clinical settings, with 761 studies meeting \n",
      "the inclusion criteria. While general-domain LLMs, particularly ChatGPT and GPT-4, dominated evaluations (93.55%), \n",
      "medical-domain LLMs accounted for only 6.45%. Accuracy emerged as the most commonly assessed parameter \n",
      "(21.78%). Despite these advancements, the evidence base highlights certain limitations and biases across the \n",
      "included studies, emphasizing the need for careful interpretation and robust evaluation frameworks.\n",
      "Conclusions  The exponential growth in LLM research underscores their transformative potential in healthcare. \n",
      "However, addressing challenges such as ethical risks, evaluation variability, and underrepresentation of critical \n",
      "specialties will be essential. Future efforts should prioritize standardized frameworks to ensure safe, effective, and \n",
      "equitable LLM integration in clinical practice.\n",
      "Keywords  Systematic review, Large language models, LLM evaluation, Clinical medicine, Artificial intelligence in \n",
      "medicine, Deep learning in healthcare, Natural language processing\n",
      "A systematic review of large language model \n",
      "(LLM) evaluations in clinical medicine\n",
      "Sina Shool1, Sara Adimi2, Reza Saboori Amleshi1, Ehsan Bitaraf1, Reza Golpira2 and Mahmood Tara1,2*\n",
      "Page 2 of 11\n",
      "Shool et al. BMC Medical Informatics and Decision Making          (2025) 25:117 \n",
      "Background\n",
      "Background Large language models (LLMs) are advanced \n",
      "AI systems based on transformer architectures, designed \n",
      "to process and generate human language by modeling the \n",
      "probabilistic relationships between tokens in a sequence. \n",
      "Unlike traditional AI models, LLMs are pre-trained on \n",
      "massive datasets, enabling them to learn complex linguis­\n",
      "tic patterns and adapt to diverse tasks through fine-tun­\n",
      "ing or prompting. This differentiates LLMs from broader \n",
      "categories like generative AI and neural networks, which \n",
      "may encompass non-linguistic or less context-sensitive \n",
      "models [1].\n",
      "LLMs can be categorized into three primary types:\n",
      " \t•\n",
      "Encoder-only models (e.g., BERT, DeBERTa): \n",
      "Specializing in understanding text for tasks such as \n",
      "classification and sentiment analysis.\n",
      " \t•\n",
      "Decoder-only models (e.g., GPT-series, PaLM): \n",
      "Excelling in text generation and language modeling.\n",
      " \t•\n",
      "Encoder-decoder models (e.g., T5, ChatGLM): \n",
      "Designed for tasks requiring both understanding and \n",
      "generation, such as summarization and translation.\n",
      "In healthcare, LLMs have shown potential in various \n",
      "applications. For instance, ChatGPT has demonstrated \n",
      "utility in medical education by generating differential \n",
      "diagnoses and answering exam-style questions, achieving \n",
      "performance comparable to human experts in USMLE \n",
      "tests. Similarly, models like MedPaLM-2 and MedPrompt \n",
      "have been fine-tuned for specific medical tasks, ranging \n",
      "from electronic health record (EHR) analysis to generat­\n",
      "ing patient discharge summaries. Despite these advances, \n",
      "challenges such as mitigating biases, ensuring data secu­\n",
      "rity, and addressing ethical concerns remain critical for \n",
      "their broader adoption [1].\n",
      "The advent of large language models (LLMs) like Chat­\n",
      "GPT in healthcare marks a significant shift, potentially \n",
      "transforming medical practices across patient data man­\n",
      "agement, clinical research, and direct care. As digital \n",
      "technologies progress, research explores LLMs’ practical \n",
      "applications and efficacy within clinical environments. \n",
      "Notable studies, including those by Cascella et al., assess \n",
      "ChatGPT’s implementation viability, revealing its broad \n",
      "utility from enhancing patient communications to aiding \n",
      "clinical decision-making [2].\n",
      "LLMs promise substantial advancements by swiftly \n",
      "processing extensive medical literature and data, poten­\n",
      "tially revolutionizing decision support systems, person­\n",
      "alizing interactions, and supporting complex tasks like \n",
      "surgical planning as Tustumi et al. discuss [3]. Such inno­\n",
      "vations aim not only for increased efficiency but also for \n",
      "improved diagnostic accuracy and patient management. \n",
      "Yet, deploying these sophisticated tools invites critical \n",
      "discussions on their reliability, security, and ethical use, \n",
      "especially given the sensitive nature of healthcare. As \n",
      "highlighted in Nature Medicine, these technologies pres­\n",
      "ent both significant opportunities and challenges in the \n",
      "medical field [4]. Furthermore, Lahat and Klang argue \n",
      "that LLMs can help meet rising demands for special­\n",
      "ized medical services and enhance telehealth, crucial for \n",
      "addressing global health disparities [5].\n",
      "The rising importance of LLMs necessitates improved \n",
      "evaluation frameworks and interdisciplinary efforts to \n",
      "enhance their clinical integration and ensure safety and \n",
      "effectiveness​. This systematic review aims to examine the \n",
      "evaluations of LLMs within medical and clinical fields.\n",
      "Methods\n",
      "A comprehensive literature search was conducted on \n",
      "January 15, 2025, using databases such as PubMed, Sco­\n",
      "pus, Web of Science, arXiv, and IEEE Xplore. The search \n",
      "employed keywords and MeSH terms related to “evalua­\n",
      "tion,” “large language models,” “artificial intelligence chat­\n",
      "bot,” and “medical and clinical practice,” as detailed in \n",
      "Appendix Table (Table S1).\n",
      "Inclusion criteria\n",
      "The review included original research articles assess­\n",
      "ing LLMs within medical contexts, requiring that both \n",
      "abstracts and full texts were accessible. No limitations \n",
      "were imposed regarding publication date or language.\n",
      "Exclusion criteria\n",
      "Non-original articles, including reviews, letters, edito­\n",
      "rials, and conference papers, were excluded, along with \n",
      "articles lacking abstracts, those not specifying evalua­\n",
      "tion parameters, or those focusing on non-LLM models. \n",
      "Multimodal Large Language Models (MLLMs), Large \n",
      "Vision Language Models (e.g., ChatGPT 4v, LVLM, llava), \n",
      "Vision-Language Processing (VLP) models, Vision mod­\n",
      "els, Small Language Models, and general Language Mod­\n",
      "els (only Large Language Models would be included) \n",
      "were also excluded.\n",
      "Study selection\n",
      "The initial search identified multiple records, which were \n",
      "deduplicated and screened for relevance. Articles failing \n",
      "to meet inclusion criteria were systematically excluded \n",
      "per PRISMA guidelines [5]. The study selection process \n",
      "adhered to the PRISMA guidelines, and a PRISMA flow \n",
      "diagram was used to illustrate the selection process.\n",
      "Data extraction\n",
      "The remaining articles underwent detailed data extrac­\n",
      "tion, removing entries without accessible abstracts or \n",
      "full texts, missing DOIs, duplicates, and non-original \n",
      "research. The process involved answering 11 key ques­\n",
      "tions, as outlined in Table (Table 1), ensuring a thorough \n",
      "Page 3 of 11\n",
      "Shool et al. BMC Medical Informatics and Decision Making          (2025) 25:117 \n",
      "and unbiased review of evaluation of LLM performance \n",
      "in healthcare contexts.\n",
      "Titles and abstracts were independently screened by \n",
      "two reviewers to assess relevance against the inclusion \n",
      "and exclusion criteria. Full-text articles of potentially \n",
      "eligible studies were retrieved and independently evalu­\n",
      "ated by the same reviewers. Any disagreements regarding \n",
      "study eligibility were resolved through discussion. If con­\n",
      "sensus could not be reached, a third reviewer was con­\n",
      "sulted to adjudicate and reach a final decision.\n",
      "The percentages represent the proportion of studies \n",
      "within each group that evaluated a specific parameter. \n",
      "This approach ensures a clear understanding of how \n",
      "widely a parameter was assessed in relation to its group \n",
      "context.\n",
      "Human evaluation methods varied across studies, \n",
      "including expert raters, peer evaluations, and crowd­\n",
      "sourcing. However, few studies reported using standard­\n",
      "ized rubrics or guidelines, which may affect reliability \n",
      "and consistency. This variability highlights the need for \n",
      "more standardized evaluation frameworks to ensure uni­\n",
      "formity in future assessments. While this review focuses \n",
      "on identifying evaluation parameters, future studies \n",
      "could systematically categorize and analyze evaluation \n",
      "methods.\n",
      "Results\n",
      "Study selection and data extraction\n",
      "A comprehensive search across PubMed, Scopus, Web \n",
      "of Science, arXiv, and IEEE Xplore yielded 25,156 stud­\n",
      "ies, from which 2754 duplicates and 328 additional \n",
      "records were removed (Fig.  1). This resulted in 22,074 \n",
      "records being screened by title and abstract, leading to \n",
      "the exclusion of 20,198 for not meeting inclusion criteria. \n",
      "Following this, data extraction was performed on 1876 \n",
      "articles that passed the initial screening. Of these, 586 \n",
      "articles were excluded due to reasons such as inaccessible \n",
      "abstracts or full texts, lack of DOI, duplication, and non-\n",
      "original research types.\n",
      "Following a detailed full-text review, an additional \n",
      "529 articles were excluded. Ultimately, this rigorous and \n",
      "meticulous effort culminated in 761 articles from which \n",
      "data was fully extracted, as documented in Appendix \n",
      "Table (Table S2). [This appendix table represents a cor­\n",
      "nerstone of the study, containing the most comprehen­\n",
      "sive data compilation from the included articles. Due to \n",
      "its considerable length and detail—spanning over 100 \n",
      "pages—it could not be incorporated into the main manu­\n",
      "script but is made available in its entirety to ensure trans­\n",
      "parency and to highlight the exhaustive work underlying \n",
      "this research. Readers are strongly encouraged to con­\n",
      "sult Appendix Table S2 to fully appreciate the depth and \n",
      "scope of the extracted data.]\n",
      "The evaluation of publications from 2019 to 2025 \n",
      "shows a notable exponential increase in research output, \n",
      "particularly evident from 2021 onwards. In 2019, only 1 \n",
      "article was published, increasing to 3 in 2020, 6 in 2021, 7 \n",
      "in 2022, and dramatically rising to 160 in 2023. This trend \n",
      "continued into 2024, with 557 articles published, fol­\n",
      "lowed by 27 articles in early 2025, highlighting a marked \n",
      "growth in research activity over this period.\n",
      "Summary of LLMs evaluated\n",
      "The studies evaluated a total of 1,534 instances of LLMs. \n",
      "Among these, the majority were general-domain LLMs, \n",
      "accounting for 1,435 records (93.55%). In contrast, med­\n",
      "ical-domain LLMs were assessed in 99 records, making \n",
      "up 6.45% of the total.\n",
      "Among the 1,435 general-domain LLMs, the majority \n",
      "were decoder-only models, accounting for 1,340 records \n",
      "(93.4%). Encoder-decoder models were evaluated in 21 \n",
      "records (1.5%), while encoder-only models were assessed \n",
      "in 74 records (5.2%).\n",
      "In the medical-domain LLMs (99 records), decoder-\n",
      "only models dominated with 79 records (79.8%). \n",
      "Encoder-decoder models were mentioned in 4 records \n",
      "(4.0%), and encoder-only models in 14 records (14.1%). \n",
      "For 2 records (2.0%), the architecture type was not explic­\n",
      "itly detailed.\n",
      "Among the 1,340 decoder-only general-domain LLMs, \n",
      "ChatGPT was the most frequently evaluated, with 242 \n",
      "records (18.1%), followed by ChatGPT-4 (175 records, \n",
      "13.1%), GPT-4 (165 records, 12.3%), and ChatGPT-3.5 \n",
      "(139 records, 10.4%). Google PaLM 2/Bard/Gemini was \n",
      "assessed in 118 records (8.8%), while GPT-3.5 appeared \n",
      "Table 1  Key questions for data extraction\n",
      "Q1\n",
      "Based on the article provided, which medical field does \n",
      "this article pertain to?\n",
      "Q2\n",
      "Is the language of the article a non-English language? \n",
      "(yes = 1, No = 0)\n",
      "Q3\n",
      "Is an LLM or GPT mentioned in the article used for educa­\n",
      "tional purposes in medical/clinical field? (yes = 1, No = 0)\n",
      "Q4\n",
      "Is an LLM or GPT mentioned in the article used for exami­\n",
      "nation and evaluating purposes in medical/clinical field? \n",
      "(yes = 1, No = 0)\n",
      "Q5\n",
      "Is the evaluation of the LLM or GPT conducted by hu­\n",
      "mans or compared with humans? (yes = 1, No = 0)\n",
      "Q6\n",
      "What is the name of the LLM(s) or GPT(s) version evalu­\n",
      "ated in the article?\n",
      "Q7\n",
      "What is the targeted group of interest for the LLM or GPT \n",
      "mentioned in the article (e.g., doctors, nurses, students, \n",
      "patients)?\n",
      "Q8\n",
      "How are the responses of the LLM evaluated?\n",
      "Q9\n",
      "What is the gold standard against which the LLM’s \n",
      "responses are compared?\n",
      "Q10\n",
      "What tools, scales, or set of questions are used in the \n",
      "evaluation, and how many questions are there?\n",
      "Q11\n",
      "What parameters are assessed to measure the LLM’s \n",
      "responses?\n",
      "Page 4 of 11\n",
      "Shool et al. BMC Medical Informatics and Decision Making          (2025) 25:117 \n",
      "in 58 records (4.3%). Other models included Meta Llama \n",
      "2 (46 records, 3.4%), Microsoft Copilot/Bing (44 records, \n",
      "3.3%), Meta Llama 3 (41 records, 3.1%), and Anthropic \n",
      "Claude (39 records, 2.9%).\n",
      "Smaller groups of models included Mistral (27 records, \n",
      "2.0%), Qwen (2.5-72b) (20 records, 1.5%), GPT-3.5 Turbo \n",
      "(19 records, 1.4%), GPT-4o (14 records, 1.0%), ChatGPT-\n",
      "4o and Mixtral (each with 11 records, 0.8%), and Llama \n",
      "Fig. 1  PRISMA flow diagram for systematic reviews which included searches of databases\n",
      " \n",
      "Page 5 of 11\n",
      "Shool et al. BMC Medical Informatics and Decision Making          (2025) 25:117 \n",
      "(10 records, 0.7%). Models such as Baichuan (9 records, \n",
      "0.7%), Perplexity AI (8 records, 0.6%), GPT models, \n",
      "Vicuna, PMC-LLaMA, and Gemma (each with 7 records, \n",
      "0.5%) followed.\n",
      "A variety of models were evaluated in fewer than six \n",
      "records, such as GPT-4 Turbo, InternLM, ChatGPT (cus­\n",
      "tomized), GPT-4o mini, and GPT-2, all with five records \n",
      "(0.4%). Models like GPT-3, ChatGPT3.5-turbo, ERNIE \n",
      "Bot, and ChatGPT-3 were each assessed in four records \n",
      "(0.3%). Numerous other models, including Yi-C, OpenAI \n",
      "o1-mini, ChatGPT+, and WizardLM, were evaluated in \n",
      "three records (0.2%).\n",
      "The remaining models, including OpenAI o1-preview, \n",
      "Falcon, InstructGPT, and others, were assessed in two \n",
      "or fewer records (0.1%), with many—such as Baize-\n",
      "Healthcare, Alpaca, and DanteLLM_instruct_7b-v0.2-\n",
      "boosted—evaluated only once.\n",
      "Among the 21 general-domain encoder-decoder LLMs, \n",
      "ChatGLM was the most frequently evaluated, appear­\n",
      "ing in 9 records (42.9%). Both Flan-T5 and GLM-4 were \n",
      "each evaluated in 4 records (19.0%), while BART was \n",
      "assessed in 3 records (14.3%). FLAN-UL2 was evaluated \n",
      "in 1 record (4.8%).\n",
      "Among the 74 encoder-only general-domain LLMs, \n",
      "BERT was the most frequently evaluated, appearing in \n",
      "34 records (45.9%), followed by RoBERTa in 9 records \n",
      "(12.2%) and BioBERT in 7 records (9.5%). SciBERT and \n",
      "ALBERT were each assessed in 3 records (4.1%). AfroX­\n",
      "LMR and M-BERT were evaluated in 2 records each \n",
      "(2.7%).\n",
      "Several models were evaluated only once (1.4%), \n",
      "including AfriBERTa-large, AfroLM-active-l, Camem­\n",
      "BERT-with-Dates, KoBERT, ELECTRA, DNA-BERT, \n",
      "CH-BERT, \n",
      "AlphaBERT, \n",
      "SentenceBERT, \n",
      "DistilBERT, \n",
      "DeBERTa, ColBERT, and CliRoberta (domain-adaptive \n",
      "pre-trained LLM).\n",
      "Among the 79 decoder-only medical-domain LLMs, \n",
      "the most frequently evaluated were Meditron and Huatu­\n",
      "oGPT, each appearing in 10 records (12.7%). BioMistral \n",
      "followed with 6 records (7.6%), while BioGPT was evalu­\n",
      "ated in 5 records (6.3%). PULSE, MedAlpaca, and Ascle­\n",
      "pius were each assessed in 4 records (5.1%).\n",
      "Other models included MMed-Llama, which was eval­\n",
      "uated in 3 records (3.8%), and several models, including \n",
      "DocOA, ChatMed, BianQue, BenTsao, and BioMedLM, \n",
      "each assessed in 2 records (2.5%).\n",
      "The remaining models, such as SenseNova, Collec­\n",
      "tiveSFT-7B, Clinical Camel (70B), GutGPT, Doctor \n",
      "PuJiang (Dr. PJ), ChatDoctor, AntGLM-Med-10, MedL­\n",
      "lama2, MedGPT-7B, MedicalGPT, EyeGPT (fine-tuned \n",
      "version of Llama2), Drug-GPT, DermGPT, Aeyeconsult \n",
      "(based on GPT-4), MedLM Medium, MedPaLM, Med42 \n",
      "(based on Llama-2), HyperCLOVA X, Hermes7b_ITA \n",
      "(Nous-Hermes-llama-2-7b), EthioLLM-large, EthioLLM, \n",
      "ACS-GPT, and DrBode models, were each evaluated in 1 \n",
      "record (1.3%).\n",
      "Among the 4 encoder-decoder medical-domain LLMs, \n",
      "all were evaluated in a single record (25.0% each). These \n",
      "included MOPH (a Chinese-specific ophthalmic LLM), \n",
      "BiomedNLP, CLINGEN (a knowledge-infused LLM \n",
      "model), and Clinical-T5-Large.\n",
      "Among the 14 encoder-only medical-domain LLMs, \n",
      "GatorTron and BioClinicalBERT were the most fre­\n",
      "quently evaluated, each appearing in 3 records (21.4%). \n",
      "The remaining models, including MoLFormer-XL (Pro­\n",
      "tein-specific LLMs), CancerBERT, MentalBERT, Clini­\n",
      "calBERT, BioMed-RoBERTa, and BioALBERT, were each \n",
      "evaluated in 1 record (7.1%).\n",
      "Among the medical-domain LLMs with architecture \n",
      "not explicitly detailed, two models were evaluated, each \n",
      "appearing in 1 record (50.0%). These included LICT \n",
      "(Large language model-based Identifier for Cell Types) \n",
      "and ClinicLLM (an LLM trained on [HOSPITAL]’s clini­\n",
      "cal notes).\n",
      "Major specialties evaluated\n",
      "In total, the studies analyzed 781 records, providing a \n",
      "comprehensive overview of the distribution of medical \n",
      "specialties in this research. Surgery was the most fre­\n",
      "quently evaluated specialty, accounting for 220 records \n",
      "(28.2%). Within surgery, ophthalmology was the most \n",
      "common subspecialty, with 55 records (25.0%), followed \n",
      "by orthopedics with 44 records (20.0%), and urology and \n",
      "otolaryngology each with 31 records (14.1%). Plastic sur­\n",
      "gery accounted for 20 records (9.1%), while general sur­\n",
      "gery was represented in 12 records (5.5%). Less common \n",
      "subspecialties included obstetrics and gynecology with 6 \n",
      "records (2.7%), neurosurgery and bariatric surgery with 5 \n",
      "records each (2.3%), hand surgery with 3 records (1.4%), \n",
      "vascular, laparoscopic, and spine surgery each with 2 \n",
      "records (0.9%), and trauma and thoracic surgery each \n",
      "with 1 record (0.5%).\n",
      "Internal medicine was the second most frequently eval­\n",
      "uated specialty, with 119 records (15.2%). Within internal \n",
      "medicine, oncology was the predominant subspecialty, \n",
      "accounting for 56 records (47.1%), followed by endocri­\n",
      "nology with 22 records (18.5%), gastroenterology and \n",
      "hepatology with 18 records (15.1%), rheumatology with 8 \n",
      "records (6.7%), nephrology with 6 records (5.0%), hema­\n",
      "tology with 5 records (4.2%), pulmonology with 3 records \n",
      "(2.5%), and general internal medicine with 1 record \n",
      "(0.8%).\n",
      "Medical informatics was the third most commonly \n",
      "evaluated specialty, with 112 records (14.3%), followed \n",
      "by radiology with 64 records (8.2%) and general medicine \n",
      "with 53 records (6.8%). Medical education was assessed \n",
      "in 52 records (6.7%), while neurology was evaluated in 40 \n",
      "records (5.1%), and psychiatry in 30 records (3.8%).\n",
      "Page 6 of 11\n",
      "Shool et al. BMC Medical Informatics and Decision Making          (2025) 25:117 \n",
      "Emergency medicine was represented in 21 records \n",
      "(2.7%), cardiology in 15 records (1.9%), dermatology in \n",
      "11 records (1.4%), and pediatrics in 10 records (1.3%). \n",
      "Pathology accounted for 7 records (0.9%), radiation \n",
      "oncology for 5 records (0.6%), and infectious diseases and \n",
      "anesthesiology each for 4 records (0.5%). Nuclear medi­\n",
      "cine and geriatrics each accounted for 3 records (0.4%), \n",
      "and family medicine and sports medicine each for 2 \n",
      "records (0.3%). Finally, chronic diseases, patient educa­\n",
      "tion, physical medicine and rehabilitation (physiatry), \n",
      "and sleep medicine were each evaluated in 1 record \n",
      "(0.1%).\n",
      "Target audience for LLMs evaluation\n",
      "The Target audience for LLMs evaluation includes a \n",
      "total of 976 instances, distributed across various tar­\n",
      "geted groups of interest. Doctors constitute the largest \n",
      "group, with 306 instances (31.4%), followed by patients, \n",
      "accounting for 260 instances (26.6%). Medical and \n",
      "healthcare professionals and researchers make up sig­\n",
      "nificant portions, with 100 instances (10.2%) and 98 \n",
      "instances (10.0%), respectively.\n",
      "Students and residents together represent 103 \n",
      "instances, with students contributing 72 instances (7.4%) \n",
      "and residents 31 instances (3.2%). Smaller groups include \n",
      "healthcare providers at 19 instances (1.9%), caregiv­\n",
      "ers with 10 instances (1.0%), nurses and general people \n",
      "each with 7 instances (0.7%), and families or parents of \n",
      "patients contributing 13 instances (1.3%). Educators (6 \n",
      "instances, 0.6%) and learners (3 instances, 0.3%) are the \n",
      "least represented categories.\n",
      "Lastly, 44 instances (4.5%) fall under the “others or not \n",
      "mentioned” category, representing data that does not \n",
      "pertain to the primary groups of interest.\n",
      "Grouping and evaluation criteria for LLM studies\n",
      "The studies were categorized into various groups based \n",
      "on specific criteria. as follows:\n",
      " \t•\n",
      "Group A-e: Studies where the language assessed was \n",
      "exclusively English, as determined by the answer to \n",
      "Q2.\n",
      " \t•\n",
      "Group A-ne: Studies where the languages assessed \n",
      "included non-English languages or languages other \n",
      "than English, as determined by the answer to Q2.\n",
      " \t•\n",
      "Group B-h: Studies where evaluations were \n",
      "conducted directly by humans or compared with \n",
      "human evaluations (e.g., experts or others), as \n",
      "determined by the positive answer to Q5.\n",
      " \t•\n",
      "Group B-nh: Studies where evaluations were not \n",
      "conducted directly by humans or were not compared \n",
      "with human evaluations, as determined by the \n",
      "negative answer to Q5.\n",
      " \t•\n",
      "Group C: Studies where LLMs were explicitly used \n",
      "for educational purposes in the medical or clinical \n",
      "field, as determined by the positive answer to Q3.\n",
      " \t•\n",
      "Group D: Studies where LLMs were specifically \n",
      "used for examination and evaluation purposes in \n",
      "the medical or clinical field, as determined by the \n",
      "positive answer to Q4.\n",
      "This categorization highlights the diverse applications \n",
      "and evaluation contexts of LLMs in medical research, \n",
      "demonstrating the various ways these models are inte­\n",
      "grated and assessed within the field.\n",
      "Evaluation parameters\n",
      "A comprehensive analysis of evaluation parameters \n",
      "across the 761 studies, as summarized in Table S2 (col­\n",
      "umn Q11), revealed 2,239 instances of parameter usage. \n",
      "After filtering for parameters that appeared in more than \n",
      "1% of the total instances, 16 parameters were identi­\n",
      "fied as the most frequently evaluated. These parameters, \n",
      "recorded verbatim from the studies, reflect the diverse \n",
      "approaches used to assess large language models (LLMs) \n",
      "in various contexts, particularly in the medical and clini­\n",
      "cal fields.\n",
      "Figure 2 presents the percentage distribution of these \n",
      "parameters, both across the total dataset and within \n",
      "specific study groups, highlighting variations in focus \n",
      "depending on the application or evaluation criteria.\n",
      "1.\t Accuracy was the most commonly assessed \n",
      "parameter, appearing in 419 instances, representing \n",
      "21.78% of evaluations in Group A-e, 22.99% in Group \n",
      "A-ne, 21.64% in Group B-h, 21.84% in Group B-nh, \n",
      "20.38% in Group C, and 24.31% in Group D.\n",
      "2.\t Consistency was evaluated in 33 instances (2.19% \n",
      "in Group A-e, 2.20% in Group A-ne, 1.46% in Group \n",
      "B-h, 2.15% in Group B-nh, 2.23% in Group C, and \n",
      "3.45% in Group D).\n",
      "3.\t Performance was recorded in 34 instances, with \n",
      "notable percentages in Group A-ne (6.95%), Group \n",
      "B-h (4.68%), and Group D (5.17%), compared to \n",
      "1.95% in Group A-e, 1.99% in Group B-nh, and 2.65% \n",
      "in Group C.\n",
      "4.\t Reliability was assessed in 46 instances, with \n",
      "relatively higher percentages in Group B-nh (2.70%) \n",
      "and Group C (2.97%) compared to other groups.\n",
      "5.\t Clarity was evaluated in 35 instances but remained \n",
      "less prominent in most groups (< 1.0% in Group B-h \n",
      "and Group D), with slightly higher percentages in \n",
      "Group B-nh (2.10%) and Group C (2.44%).\n",
      "6.\t Quality was reported in 43 instances, with its \n",
      "highest percentage in Group C (3.82%) and modest \n",
      "levels in Group A-e (2.88%) and Group B-nh (2.76%).\n",
      "Page 7 of 11\n",
      "Shool et al. BMC Medical Informatics and Decision Making          (2025) 25:117 \n",
      "7.\t Readability was a major focus, evaluated in 95 \n",
      "instances, showing significant emphasis in Group \n",
      "C (6.48%) and consistent usage across Groups A-e \n",
      "(4.29%), A-ne (4.81%), and B-h (4.68%).\n",
      "8.\t Reasoning appeared in 13 instances, with notable \n",
      "percentages in Group A-ne (2.14%) and Group D \n",
      "(2.76%), while being evaluated at < 1.0% in other \n",
      "groups.\n",
      "9.\t Comprehensiveness, assessed in 47 instances, was \n",
      "most emphasized in Group C (3.29%) and Group \n",
      "A-ne (3.20%), with smaller percentages in other \n",
      "groups.\n",
      "10.\tCompleteness, appearing in 49 instances, was \n",
      "consistently evaluated across most groups, with the \n",
      "highest percentage in Group B-nh (2.81%).\n",
      "11.\tCorrectness was recorded in 34 instances, with its \n",
      "highest emphasis in Group D (3.10%) and Group C \n",
      "(2.76%).\n",
      "Fig. 2  Distribution of evaluation parameters in total and across groups\n",
      " \n",
      "Page 8 of 11\n",
      "Shool et al. BMC Medical Informatics and Decision Making          (2025) 25:117 \n",
      "12.\tSafety was assessed in 21 instances, with small \n",
      "percentages across all groups, peaking at 1.80% in \n",
      "Group C.\n",
      "13.\tAppropriateness appeared in 24 instances, with \n",
      "modest evaluation levels across groups, peaking at \n",
      "1.65% in Group B-nh.\n",
      "14.\tRelevancy, reported in 43 instances, was evaluated \n",
      "most prominently in Group B-nh (2.43%).\n",
      "15.\tSensitivity, assessed in 31 instances, showed a \n",
      "higher focus in Group B-h (2.05%) compared to \n",
      "other groups.\n",
      "16.\tSpecificity was recorded in 30 instances, with \n",
      "modest levels across all groups, peaking at 1.46% in \n",
      "Group B-h.\n",
      "Discussion\n",
      "Evaluation types\n",
      "The assessment of large language models (LLMs) in \n",
      "healthcare requires advanced evaluation methodologies \n",
      "that prioritize context-specific metrics, safety, and accu­\n",
      "racy, surpassing traditional benchmarks. These method­\n",
      "ologies must also address critical concerns such as data \n",
      "privacy, ethical implications, and risks posed by inac­\n",
      "curacies or biases. Additionally, the unique demands of \n",
      "healthcare require LLMs to interpret and generate spe­\n",
      "cialized medical content with high reliability and contex­\n",
      "tual relevance ​ [6, 7].\n",
      "This study highlights a dramatic increase in research \n",
      "interest in LLMs in healthcare, with publications surging \n",
      "from a single study in 2019 to 557 in 2024. This exponen­\n",
      "tial growth underscores the expanding capabilities and \n",
      "clinical potential of LLMs, particularly in diagnostics, \n",
      "decision support, medical education, and patient com­\n",
      "munication. However, the lack of standardized evaluation \n",
      "tools, variability in study designs, and ethical concerns \n",
      "such as data privacy and hallucination risks represent key \n",
      "barriers to effective evaluation of LLMs in clinical set­\n",
      "tings. Addressing these issues requires interdisciplinary \n",
      "efforts and the development of robust frameworks tai­\n",
      "lored to clinical contexts​ ​ [8–10].\n",
      "Barriers\n",
      "Clinical evaluations of LLMs necessitate interdisci­\n",
      "plinary collaboration to meet the intricate demands \n",
      "of medical practice, requiring rigorous validation and \n",
      "optimization for diverse clinical applications. The grow­\n",
      "ing use in healthcare underscores the urgent need for \n",
      "standardized evaluation frameworks to assess their per­\n",
      "formance and safety effectively ​ [11–13]. While LLMs \n",
      "offer significant advancements, their rapid development \n",
      "raises ethical concerns, including the potential erosion \n",
      "of human expertise, reduced interpersonal interactions, \n",
      "and risks of misuse. For instance, AI-generated medi­\n",
      "cal advice could diminish the role of human empathy \n",
      "in patient care. Ensuring responsible development and \n",
      "deployment through regulatory oversight is critical to \n",
      "mitigate these risks and balance innovation with societal \n",
      "well-being.\n",
      "Frameworks\n",
      "While no single evaluation framework has been univer­\n",
      "sally adopted, several studies propose initial guidelines, \n",
      "emphasizing metrics such as transparency, explainabil­\n",
      "ity, and clinical relevance. These frameworks could serve \n",
      "as a foundation for future systematic evaluations. Our \n",
      "analysis of 761 studies provides a comprehensive over­\n",
      "view of the evaluation parameters and applications of \n",
      "LLMs in healthcare. The studies focused predominantly \n",
      "on general-domain LLMs (93.55%), with decoder-only \n",
      "architectures like ChatGPT and GPT-4 being the most \n",
      "frequently evaluated models. Medical-domain LLMs, \n",
      "accounting for 6.45% of studies, demonstrated early but \n",
      "promising specialization, with models such as Meditron \n",
      "and HuatuoGPT being the most assessed. However, the \n",
      "limited evaluation of encoder-decoder and encoder-only \n",
      "models, both in general and medical domains, reveals a \n",
      "gap in exploring alternative architectures. Its extensive \n",
      "use in clinical settings underscores its versatility and \n",
      "superior performance in diagnostics and generating dif­\n",
      "ferential diagnoses, reflecting its enhanced linguistic and \n",
      "contextual processing capabilities [14–16].\n",
      "Applications and trends\n",
      "The analysis underscores the evaluation of a wide array \n",
      "of LLMs, with around one thirds of studies focusing on \n",
      "GPT models like GPT-4, and specialized or customized \n",
      "variants, reflecting tailored explorations for specific clini­\n",
      "cal tasks. Other models, including Google Bard, Micro­\n",
      "soft Bing, and BERT variants, along with Claude, Llama, \n",
      "and PaLM2, are also reviewed, pointing to a vibrant AI \n",
      "research landscape in healthcare. Yet, the limited assess­\n",
      "ment of these models highlights the necessity for stan­\n",
      "dardized evaluation frameworks to enable effective \n",
      "comparisons ​ [17].​.\n",
      "The evaluation of LLMs in healthcare reveals sig­\n",
      "nificant variations in research focus and application, \n",
      "underscoring the critical need to align research priori­\n",
      "ties with clinical demands. Surgery emerged as the most \n",
      "frequently evaluated specialty, representing 28.2% of all \n",
      "studies, reflecting its prominent role in healthcare. How­\n",
      "ever, critical specialties such as cardiology (1.9%) and \n",
      "emergency medicine (2.7%) remain significantly under­\n",
      "represented despite their global importance. These find­\n",
      "ings highlight the necessity for future research to target \n",
      "high-burden and underserved areas to maximize the \n",
      "potential impact of LLMs in clinical practice.\n",
      "Page 9 of 11\n",
      "Shool et al. BMC Medical Informatics and Decision Making          (2025) 25:117 \n",
      "Subspecialty analysis\n",
      "The analysis of subspecialties within surgery emphasizes \n",
      "the dominance of ophthalmology (25.0%), orthopedics \n",
      "(20.0%), and urology and otolaryngology (14.1% each). \n",
      "Despite their importance, general surgery (5.5%) and \n",
      "other subspecialties, including neurosurgery and vascu­\n",
      "lar surgery, were evaluated far less frequently, highlight­\n",
      "ing potential gaps in research coverage. Similarly, internal \n",
      "medicine—a key specialty—was the second most evalu­\n",
      "ated area (15.2%), with oncology (47.1%) leading among \n",
      "its subspecialties. However, other critical areas, such as \n",
      "nephrology (5.0%) and pulmonology (2.5%), were mini­\n",
      "mally represented, signaling the need for broader evalua­\n",
      "tions within this domain. Future research should focus on \n",
      "aligning LLM evaluations with the specific clinical needs \n",
      "of diverse medical specialties to ensure their effective and \n",
      "responsible integration into healthcare practice [4, 6].\n",
      "Parameter evaluations\n",
      "A total of 2,239 parameter evaluations were identified, \n",
      "with accuracy emerging as the most frequently assessed \n",
      "metric (419 instances, 21.78%). This reflects the critical \n",
      "importance of producing precise and reliable outputs in \n",
      "clinical settings. Other frequently evaluated parameters, \n",
      "such as readability (95 instances, 4.29%) and reliabil­\n",
      "ity (46 instances, 2.53%), emphasize the need for out­\n",
      "puts that are both clear and dependable. Less commonly \n",
      "assessed parameters, including safety, bias, and appropri­\n",
      "ateness, highlight areas requiring more focused research \n",
      "to address potential risks and ethical challenges in clini­\n",
      "cal applications.\n",
      "Our grouping framework, based on language, applica­\n",
      "tion purposes, and evaluation methods, revealed distinct \n",
      "patterns in LLM usage and assessment:\n",
      "Group A-e and Group A-ne studies collectively empha­\n",
      "sized accuracy as a key evaluation parameter, with usage \n",
      "rates of 21.78% and 22.99%, respectively. This reflects the \n",
      "critical need for precise and dependable outputs, regard­\n",
      "less of whether the language focus was exclusively Eng­\n",
      "lish or included non-English languages. Group A-ne \n",
      "studies, which included non-English languages, showed \n",
      "a higher focus on performance (6.95%) and comprehen­\n",
      "siveness (3.20%), reflecting the challenges of evaluating \n",
      "multilingual capabilities.\n",
      "Group B-h, involving direct human evaluations, \n",
      "emphasized accuracy (21.64%) and correctness (1.80%), \n",
      "highlighting the role of expert validation in ensuring the \n",
      "clinical utility of LLM outputs.\n",
      "Group B-nh, which relied on automated or indi­\n",
      "rect evaluations, focused on metrics like completeness \n",
      "(2.81%) and quality (2.76%), reflecting the need for reli­\n",
      "able outputs in contexts without human oversight.\n",
      "Group \n",
      "C, \n",
      "addressing \n",
      "educational \n",
      "applications, \n",
      "placed significant emphasis on readability (6.48%) and \n",
      "comprehensiveness (3.29%), crucial for effective knowl­\n",
      "edge dissemination.\n",
      "Group D, targeting examination and evaluation pur­\n",
      "poses, highlighted accuracy (24.31%) and correctness \n",
      "(3.10%) as key metrics, underscoring the importance of \n",
      "dependable outputs in high-stakes contexts.\n",
      "These group-specific analyses provide valuable insights \n",
      "into how LLMs are assessed across diverse research con­\n",
      "texts, reflecting the tailored objectives and priorities of \n",
      "each group. Notably, the limited focus on ethical param­\n",
      "eters like safety and bias across all groups highlights a \n",
      "critical gap that must be addressed to ensure equitable \n",
      "and responsible LLM integration.\n",
      "Limitations\n",
      "The evaluation of LLMs in healthcare highlights their \n",
      "varied applications and categorization by language and \n",
      "methods. Nonetheless, several issues persist, includ­\n",
      "ing an excessive focus on accuracy, which does not ade­\n",
      "quately capture the complexity of model performance in \n",
      "clinical settings. Essential factors like safety, fairness, and \n",
      "bias are often neglected, and many studies rely on closed-\n",
      "ended tasks, failing to mirror the complexity of clinical \n",
      "decision-making which requires comprehensive, open-\n",
      "ended reasoning ​ [8, 18].\n",
      "Additionally, the categorization of studies by language \n",
      "and purpose reveals varied applications of LLMs and \n",
      "underscores a lack of standardized evaluation practices. \n",
      "This fragmentation impedes a unified understanding of \n",
      "LLMs’ capabilities across medical fields. Moreover, the \n",
      "application of LLMs in clinical settings faces challenges, \n",
      "as the lack of domain-specific training data can cause \n",
      "inaccuracies, especially in precise fields like radiology or \n",
      "genetics ​ [6, 19].\n",
      "A notable limitation of this study is the restriction of \n",
      "the search strategy to titles of published studies. This \n",
      "approach, while providing a focused scope, may have \n",
      "excluded relevant studies identifiable through abstracts. \n",
      "Future systematic reviews in this domain should consider \n",
      "expanding the search strategy to include both titles and \n",
      "abstracts to ensure a more comprehensive capture of eli­\n",
      "gible studies.\n",
      "The lack of standardized definitions for some evalua­\n",
      "tion parameters and the variability in human evaluation \n",
      "practices are recognized as limitations of this review. \n",
      "While this work identifies trends in parameter usage \n",
      "and grouping criteria, future research should explore \n",
      "standardizing these definitions and frameworks within \n",
      "specific medical specialties or model types. Some find­\n",
      "ings, such as the distribution of clinical specialties and \n",
      "target audiences, provide contextual insights but are not \n",
      "directly aligned with the primary focus on evaluation \n",
      "methods. Future reviews could streamline the analysis to \n",
      "align more closely with evaluation frameworks.\n",
      "Page 10 of 11\n",
      "Shool et al. BMC Medical Informatics and Decision Making          (2025) 25:117 \n",
      "Future directions and perspectives\n",
      "To fully realize the potential of large language models \n",
      "(LLMs) in healthcare, future efforts should prioritize sev­\n",
      "eral key areas. First, enhancing interpretability is criti­\n",
      "cal to developing transparent models that clinicians can \n",
      "trust for reliable decision support. Establishing robust \n",
      "validation frameworks tailored to the complexities of \n",
      "clinical settings is equally essential to ensure the accu­\n",
      "racy and applicability of LLM outputs. Ethical consider­\n",
      "ations, such as safeguarding data privacy, mitigating bias, \n",
      "and addressing the societal impacts of automation, must \n",
      "also be a primary focus. Additionally, the evolving roles \n",
      "of healthcare professionals require exploration, as these \n",
      "technologies may shift their responsibilities from deci­\n",
      "sion-makers to supervisors of AI-generated insights. To \n",
      "mitigate risks associated with misuse or overreliance on \n",
      "LLMs, the development of comprehensive governance \n",
      "frameworks is imperative, ensuring their deployment \n",
      "aligns with ethical and safety standards. Finally, address­\n",
      "ing barriers to adoption, including resource constraints \n",
      "and resistance to change, will require interdisciplinary \n",
      "collaboration and targeted education efforts to foster \n",
      "acceptance and successful integration into healthcare \n",
      "practices.\n",
      "Conclusions\n",
      "This systematic review underscores the expanding role of \n",
      "LLMs in clinical medicine, highlighting their potential to \n",
      "revolutionize medical diagnostics, education, and patient \n",
      "care. While their applications are diverse, critical chal­\n",
      "lenges remain, including the need for standardized evalu­\n",
      "ation frameworks, attention to ethical considerations, \n",
      "and the underrepresentation of high-priority medical \n",
      "specialties. Addressing these challenges through inter­\n",
      "disciplinary collaboration and robust governance will \n",
      "be essential for the responsible deployment of LLMs. \n",
      "Future research should focus on enhancing model inter­\n",
      "pretability, tailoring evaluations to clinical complexities, \n",
      "and addressing disparities in specialty-specific applica­\n",
      "tions. By aligning technological advancements with clini­\n",
      "cal needs, LLMs can drive significant improvements in \n",
      "healthcare outcomes.\n",
      "Abbreviations\n",
      "LLM\t\n",
      "\u0007Large Language Model\n",
      "Supplementary Information\n",
      "The online version contains supplementary material available at ​h​t​t​p​s​:​/​/​d​o​i​.​o​r​\n",
      "g​/​1​0​.​1​1​8​6​/​s​1​2​9​1​1​-​0​2​5​-​0​2​9​5​4​-​4.\n",
      "Supplementary Material 1\n",
      "Acknowledgements\n",
      "Not applicable.\n",
      "Author contributions\n",
      "SS, EB, and MT conceptualized the study, developed the methodology, \n",
      "and conducted the initial literature review. SS and RSA were responsible \n",
      "for data extraction, analysis, and synthesis of the findings. EB, SA, and RG \n",
      "contributed to the interpretation of the results and provided critical revisions \n",
      "to the manuscript. MT supervised the project, provided expert guidance on \n",
      "the clinical applications of LLMs, and contributed to the final review of the \n",
      "manuscript. All authors read and approved the final manuscript.\n",
      "Funding\n",
      "This research received no specific grant from any funding agency in the \n",
      "public, commercial, or not-for-profit sectors.\n",
      "Data availability\n",
      "All data generated or analyzed during this study are included in this published \n",
      "article and its supplementary files.\n",
      "Declarations\n",
      "Ethics approval and consent to participate\n",
      "Not applicable.\n",
      "Consent for publication\n",
      "Not applicable.\n",
      "Competing interests\n",
      "The authors declare no competing interests.\n",
      "Received: 30 September 2024 / Accepted: 26 February 2025\n",
      "References\n",
      "1.\t\n",
      "Zhou H, Liu F, Gu B, Zou X, Huang J, Wu J et al. A survey of large language \n",
      "models in medicine: progress, application, and challenge. ArXiv Preprint. \n",
      "2023;arXiv:231105112.\n",
      "2.\t\n",
      "Cascella M, Montomoli J, Bellini V, Bignami E. Evaluating the feasibility of \n",
      "ChatGPT in healthcare: an analysis of multiple clinical and research scenarios. \n",
      "J Med Syst. 2023;47(1):33.\n",
      "3.\t\n",
      "Tustumi F, Andreollo NA, Aguilar-Nascimento, JEd. Future of the language \n",
      "models in healthcare: the role of chatGPT. ABCD arquivos brasileiros de \n",
      "cirurgia digestiva (são paulo). 2023;36:e1727.\n",
      "4.\t\n",
      "Wilhelm TI, Roos J, Kaczmarczyk R. Large language models for therapy recom­\n",
      "mendations across 3 clinical specialties: comparative study. J Med Internet \n",
      "Res. 2023;25:e49324.\n",
      "5.\t\n",
      "Lahat A, Klang E. Can advanced technologies help address the global \n",
      "increase in demand for specialized medical care and improve telehealth \n",
      "services? J Telemed Telecare. 2024;30(9).\n",
      "6.\t\n",
      "Chen X, Xiang J, Lu S, Liu Y, He M, Shi D. Evaluating large language models in \n",
      "medical applications: a survey. ArXiv Preprint. 2024;arXiv:240507468.\n",
      "7.\t\n",
      "Karabacak M, Margetis K. Embracing large language models for medical \n",
      "applications: opportunities and challenges. Cureus. 2023;15(5):e39305.\n",
      "8.\t\n",
      "Nazi ZA, Peng W. Large language models in healthcare and medical domain: \n",
      "A review. ArXiv Preprint. 2023;arXiv:240106775.\n",
      "9.\t\n",
      "Ríos-Hoyo A, Shan NL, Li A, Pearson AT, Pusztai L, Howard FM. Evaluation of \n",
      "large language models as a diagnostic aid for complex medical cases. Front \n",
      "Med. 2024;11:1380148.\n",
      "10.\t Zhou H, Liu F, Gu B, Zou X, Huang J, Wu J et al. A survey of large language \n",
      "models in medicine: principles, applications, and challenges. arXiv preprint. \n",
      "2023;arXiv:231105112.\n",
      "11.\t Busch F, Hoffmann L, Rueger C, van Dijk EHC, Kader R, Ortiz-Prado E et al. \n",
      "Systematic review of large language models for patient care: current applica­\n",
      "tions and challenges. medRxiv. 2024:2024.03.04.24303733.\n",
      "12.\t Park Y-J, Pillai A, Deng J, Guo E, Gupta M, Paget M, et al. Assessing the research \n",
      "landscape and clinical utility of large language models: a scoping review. \n",
      "BMC Med Inf Decis Mak. 2024;24(1):72.\n",
      "13.\t Perlis RH, Fihn SD. Evaluating the application of large language models in \n",
      "clinical research contexts. JAMA Netw Open. 2023;6(10):e2335924–e.\n",
      "Page 11 of 11\n",
      "Shool et al. BMC Medical Informatics and Decision Making          (2025) 25:117 \n",
      "14.\t Hoppe JM, Auer MK, Strüven A, Massberg S, Stremmel C. ChatGPT with GPT-4 \n",
      "outperforms emergency department physicians in diagnostic accuracy: \n",
      "retrospective analysis. J Med Internet Res. 2024;26:e56110.\n",
      "15.\t Mackey BP, Garabet R, Maule L, Tadesse A, Cross J, Weingarten M. Evaluating \n",
      "ChatGPT-4 in medical education: an assessment of subject exam perfor­\n",
      "mance reveals limitations in clinical curriculum support for students. Discover \n",
      "Artif Intell. 2024;4(1):38.\n",
      "16.\t Ueda D, Walston SL, Matsumoto T, Deguchi R, Tatekawa H, Miki Y. Evaluating \n",
      "GPT-4-based ChatGPT’s clinical potential on the NEJM quiz. BMC Digit Health. \n",
      "2024;2(1):4.\n",
      "17.\t Alessandri-Bonetti MGR, Naegeli M, Liu HY, Egro FM. Assessing the soft tissue \n",
      "infection expertise of ChatGPT and Bard compared to IDSA recommenda­\n",
      "tions. Ann Biomed Eng. 2023.\n",
      "18.\t Liu F, Zhou H, Hua Y, Rohanian O, Clifton L, Clifton DA. Large lan­\n",
      "guage models in healthcare: A comprehensive benchmark. MedRxiv. \n",
      "2024:2024.04.24.24306315.\n",
      "19.\t García-Méndez S, de Arriba-Pérez F. Large language models and healthcare \n",
      "alliance: potential and challenges of two representative use cases. Ann \n",
      "Biomed Eng. 2024;52(8):1928–31.\n",
      "Publisher’s note\n",
      "Springer Nature remains neutral with regard to jurisdictional claims in \n",
      "published maps and institutional affiliations.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(user_prompt_for(text, language = 'Turkish'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2cf223cd-fee1-4823-a3be-2640e260b120",
   "metadata": {},
   "outputs": [],
   "source": [
    "def massages_for(article_text, language):\n",
    "    return [\n",
    "        {'role': 'system', 'content': system_prompt},\n",
    "        {'role': 'user', 'content': user_prompt_for(article_text, language = language)}\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2ff56f23-69d7-41c3-b071-57337dcac55e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'system',\n",
       "  'content': 'You are an AI assistant specialized in reading and summarizing long texts, such as academic articles, research papers, and reports. Your task is to read the given document carefully and generate a clear, concise, and informative summary. Focus on capturing the main points, key findings,and essential information. Do not copy text directly; instead, paraphrase in a natural and readable way.The summary should help the reader quickly understand the purpose and content of the original document and decide whether it is worth reading in full.'},\n",
       " {'role': 'user',\n",
       "  'content': 'Please read the following document and provide a well-structured summary.         Focus on the main ideas, important arguments, and key findings.         Your summary should be clear and concise, and written in natural language.         Avoid copying long passages from the text.         The goal is to help me quickly understand what the document is about. Please prepare the document with Turkish language\\n\\nDocument:\\nSYSTEMATIC REVIEW\\nOpen Access\\n© The Author(s) 2025. Open Access  This article is licensed under a Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 \\nInternational License, which permits any non-commercial use, sharing, distribution and reproduction in any medium or format, as long as you \\ngive appropriate credit to the original author(s) and the source, provide a link to the Creative Commons licence, and indicate if you modified the \\nlicensed material. You do not have permission under this licence to share adapted material derived from this article or parts of it. The images or \\nother third party material in this article are included in the article’s Creative Commons licence, unless indicated otherwise in a credit line to the \\nmaterial. If material is not included in the article’s Creative Commons licence and your intended use is not permitted by statutory regulation or \\nexceeds the permitted use, you will need to obtain permission directly from the copyright holder. To view a copy of this licence, visit \\u200bh\\u200bt\\u200bt\\u200bp\\u200b:\\u200b/\\u200b/\\u200bc\\u200br\\u200be\\u200ba\\u200bt\\u200bi\\u200b\\nv\\u200be\\u200bc\\u200bo\\u200bm\\u200bm\\u200bo\\u200bn\\u200bs\\u200b.\\u200bo\\u200br\\u200bg\\u200b/\\u200bl\\u200bi\\u200bc\\u200be\\u200bn\\u200bs\\u200be\\u200bs\\u200b/\\u200bb\\u200by\\u200b-\\u200bn\\u200bc\\u200b-\\u200bn\\u200bd\\u200b/\\u200b4\\u200b.\\u200b0\\u200b/.\\nShool et al. BMC Medical Informatics and Decision Making          (2025) 25:117 \\nhttps://doi.org/10.1186/s12911-025-02954-4\\nBMC Medical Informatics \\nand Decision Making\\n*Correspondence:\\nMahmood Tara\\nsmtara@gmail.com\\n1Center for Technology and Innovation in Cardiovascular Informatics, \\nRajaie Cardiovascular Medical and Research Center, Iran University of \\nMedical Sciences, Tehran, Iran\\n2Rajaie Cardiovascular Medical and Research Center, Iran University of \\nMedical Sciences, Tehran 1995614331, Iran\\nAbstract\\nBackground\\u2002 Large Language Models (LLMs), advanced AI tools based on transformer architectures, demonstrate \\nsignificant potential in clinical medicine by enhancing decision support, diagnostics, and medical education. \\nHowever, their integration into clinical workflows requires rigorous evaluation to ensure reliability, safety, and ethical \\nalignment.\\nObjective\\u2002 This systematic review examines the evaluation parameters and methodologies applied to LLMs in clinical \\nmedicine, highlighting their capabilities, limitations, and application trends.\\nMethods\\u2002 A comprehensive review of the literature was conducted across PubMed, Scopus, Web of Science, IEEE \\nXplore, and arXiv databases, encompassing both peer-reviewed and preprint studies. Studies were screened against \\npredefined inclusion and exclusion criteria to identify original research evaluating LLM performance in medical \\ncontexts.\\nResults\\u2002 The results reveal a growing interest in leveraging LLM tools in clinical settings, with 761 studies meeting \\nthe inclusion criteria. While general-domain LLMs, particularly ChatGPT and GPT-4, dominated evaluations (93.55%), \\nmedical-domain LLMs accounted for only 6.45%. Accuracy emerged as the most commonly assessed parameter \\n(21.78%). Despite these advancements, the evidence base highlights certain limitations and biases across the \\nincluded studies, emphasizing the need for careful interpretation and robust evaluation frameworks.\\nConclusions\\u2002 The exponential growth in LLM research underscores their transformative potential in healthcare. \\nHowever, addressing challenges such as ethical risks, evaluation variability, and underrepresentation of critical \\nspecialties will be essential. Future efforts should prioritize standardized frameworks to ensure safe, effective, and \\nequitable LLM integration in clinical practice.\\nKeywords\\u2002 Systematic review, Large language models, LLM evaluation, Clinical medicine, Artificial intelligence in \\nmedicine, Deep learning in healthcare, Natural language processing\\nA systematic review of large language model \\n(LLM) evaluations in clinical medicine\\nSina\\xa0Shool1, Sara\\xa0Adimi2, Reza\\xa0Saboori Amleshi1, Ehsan\\xa0Bitaraf1, Reza\\xa0Golpira2 and Mahmood\\xa0Tara1,2*\\nPage 2 of 11\\nShool et al. BMC Medical Informatics and Decision Making          (2025) 25:117 \\nBackground\\nBackground Large language models (LLMs) are advanced \\nAI systems based on transformer architectures, designed \\nto process and generate human language by modeling the \\nprobabilistic relationships between tokens in a sequence. \\nUnlike traditional AI models, LLMs are pre-trained on \\nmassive datasets, enabling them to learn complex linguis\\xad\\ntic patterns and adapt to diverse tasks through fine-tun\\xad\\ning or prompting. This differentiates LLMs from broader \\ncategories like generative AI and neural networks, which \\nmay encompass non-linguistic or less context-sensitive \\nmodels [1].\\nLLMs can be categorized into three primary types:\\n\\u2009\\t•\\nEncoder-only models (e.g., BERT, DeBERTa): \\nSpecializing in understanding text for tasks such as \\nclassification and sentiment analysis.\\n\\u2009\\t•\\nDecoder-only models (e.g., GPT-series, PaLM): \\nExcelling in text generation and language modeling.\\n\\u2009\\t•\\nEncoder-decoder models (e.g., T5, ChatGLM): \\nDesigned for tasks requiring both understanding and \\ngeneration, such as summarization and translation.\\nIn healthcare, LLMs have shown potential in various \\napplications. For instance, ChatGPT has demonstrated \\nutility in medical education by generating differential \\ndiagnoses and answering exam-style questions, achieving \\nperformance comparable to human experts in USMLE \\ntests. Similarly, models like MedPaLM-2 and MedPrompt \\nhave been fine-tuned for specific medical tasks, ranging \\nfrom electronic health record (EHR) analysis to generat\\xad\\ning patient discharge summaries. Despite these advances, \\nchallenges such as mitigating biases, ensuring data secu\\xad\\nrity, and addressing ethical concerns remain critical for \\ntheir broader adoption [1].\\nThe advent of large language models (LLMs) like Chat\\xad\\nGPT in healthcare marks a significant shift, potentially \\ntransforming medical practices across patient data man\\xad\\nagement, clinical research, and direct care. As digital \\ntechnologies progress, research explores LLMs’ practical \\napplications and efficacy within clinical environments. \\nNotable studies, including those by Cascella et al., assess \\nChatGPT’s implementation viability, revealing its broad \\nutility from enhancing patient communications to aiding \\nclinical decision-making [2].\\nLLMs promise substantial advancements by swiftly \\nprocessing extensive medical literature and data, poten\\xad\\ntially revolutionizing decision support systems, person\\xad\\nalizing interactions, and supporting complex tasks like \\nsurgical planning as Tustumi et al. discuss [3]. Such inno\\xad\\nvations aim not only for increased efficiency but also for \\nimproved diagnostic accuracy and patient management. \\nYet, deploying these sophisticated tools invites critical \\ndiscussions on their reliability, security, and ethical use, \\nespecially given the sensitive nature of healthcare. As \\nhighlighted in Nature Medicine, these technologies pres\\xad\\nent both significant opportunities and challenges in the \\nmedical field [4]. Furthermore, Lahat and Klang argue \\nthat LLMs can help meet rising demands for special\\xad\\nized medical services and enhance telehealth, crucial for \\naddressing global health disparities [5].\\nThe rising importance of LLMs necessitates improved \\nevaluation frameworks and interdisciplinary efforts to \\nenhance their clinical integration and ensure safety and \\neffectiveness\\u200b. This systematic review aims to examine the \\nevaluations of LLMs within medical and clinical fields.\\nMethods\\nA comprehensive literature search was conducted on \\nJanuary 15, 2025, using databases such as PubMed, Sco\\xad\\npus, Web of Science, arXiv, and IEEE Xplore. The search \\nemployed keywords and MeSH terms related to “evalua\\xad\\ntion,” “large language models,” “artificial intelligence chat\\xad\\nbot,” and “medical and clinical practice,” as detailed in \\nAppendix Table (Table S1).\\nInclusion criteria\\nThe review included original research articles assess\\xad\\ning LLMs within medical contexts, requiring that both \\nabstracts and full texts were accessible. No limitations \\nwere imposed regarding publication date or language.\\nExclusion criteria\\nNon-original articles, including reviews, letters, edito\\xad\\nrials, and conference papers, were excluded, along with \\narticles lacking abstracts, those not specifying evalua\\xad\\ntion parameters, or those focusing on non-LLM models. \\nMultimodal Large Language Models (MLLMs), Large \\nVision Language Models (e.g., ChatGPT 4v, LVLM, llava), \\nVision-Language Processing (VLP) models, Vision mod\\xad\\nels, Small Language Models, and general Language Mod\\xad\\nels (only Large Language Models would be included) \\nwere also excluded.\\nStudy selection\\nThe initial search identified multiple records, which were \\ndeduplicated and screened for relevance. Articles failing \\nto meet inclusion criteria were systematically excluded \\nper PRISMA guidelines [5]. The study selection process \\nadhered to the PRISMA guidelines, and a PRISMA flow \\ndiagram was used to illustrate the selection process.\\nData extraction\\nThe remaining articles underwent detailed data extrac\\xad\\ntion, removing entries without accessible abstracts or \\nfull texts, missing DOIs, duplicates, and non-original \\nresearch. The process involved answering 11 key ques\\xad\\ntions, as outlined in Table (Table\\xa01), ensuring a thorough \\nPage 3 of 11\\nShool et al. BMC Medical Informatics and Decision Making          (2025) 25:117 \\nand unbiased review of evaluation of LLM performance \\nin healthcare contexts.\\nTitles and abstracts were independently screened by \\ntwo reviewers to assess relevance against the inclusion \\nand exclusion criteria. Full-text articles of potentially \\neligible studies were retrieved and independently evalu\\xad\\nated by the same reviewers. Any disagreements regarding \\nstudy eligibility were resolved through discussion. If con\\xad\\nsensus could not be reached, a third reviewer was con\\xad\\nsulted to adjudicate and reach a final decision.\\nThe percentages represent the proportion of studies \\nwithin each group that evaluated a specific parameter. \\nThis approach ensures a clear understanding of how \\nwidely a parameter was assessed in relation to its group \\ncontext.\\nHuman evaluation methods varied across studies, \\nincluding expert raters, peer evaluations, and crowd\\xad\\nsourcing. However, few studies reported using standard\\xad\\nized rubrics or guidelines, which may affect reliability \\nand consistency. This variability highlights the need for \\nmore standardized evaluation frameworks to ensure uni\\xad\\nformity in future assessments. While this review focuses \\non identifying evaluation parameters, future studies \\ncould systematically categorize and analyze evaluation \\nmethods.\\nResults\\nStudy selection and data extraction\\nA comprehensive search across PubMed, Scopus, Web \\nof Science, arXiv, and IEEE Xplore yielded 25,156 stud\\xad\\nies, from which 2754 duplicates and 328 additional \\nrecords were removed (Fig.\\xa0 1). This resulted in 22,074 \\nrecords being screened by title and abstract, leading to \\nthe exclusion of 20,198 for not meeting inclusion criteria. \\nFollowing this, data extraction was performed on 1876 \\narticles that passed the initial screening. Of these, 586 \\narticles were excluded due to reasons such as inaccessible \\nabstracts or full texts, lack of DOI, duplication, and non-\\noriginal research types.\\nFollowing a detailed full-text review, an additional \\n529 articles were excluded. Ultimately, this rigorous and \\nmeticulous effort culminated in 761 articles from which \\ndata was fully extracted, as documented in Appendix \\nTable (Table S2). [This appendix table represents a cor\\xad\\nnerstone of the study, containing the most comprehen\\xad\\nsive data compilation from the included articles. Due to \\nits considerable length and detail—spanning over 100 \\npages—it could not be incorporated into the main manu\\xad\\nscript but is made available in its entirety to ensure trans\\xad\\nparency and to highlight the exhaustive work underlying \\nthis research. Readers are strongly encouraged to con\\xad\\nsult Appendix Table S2 to fully appreciate the depth and \\nscope of the extracted data.]\\nThe evaluation of publications from 2019 to 2025 \\nshows a notable exponential increase in research output, \\nparticularly evident from 2021 onwards. In 2019, only 1 \\narticle was published, increasing to 3 in 2020, 6 in 2021, 7 \\nin 2022, and dramatically rising to 160 in 2023. This trend \\ncontinued into 2024, with 557 articles published, fol\\xad\\nlowed by 27 articles in early 2025, highlighting a marked \\ngrowth in research activity over this period.\\nSummary of LLMs evaluated\\nThe studies evaluated a total of 1,534 instances of LLMs. \\nAmong these, the majority were general-domain LLMs, \\naccounting for 1,435 records (93.55%). In contrast, med\\xad\\nical-domain LLMs were assessed in 99 records, making \\nup 6.45% of the total.\\nAmong the 1,435 general-domain LLMs, the majority \\nwere decoder-only models, accounting for 1,340 records \\n(93.4%). Encoder-decoder models were evaluated in 21 \\nrecords (1.5%), while encoder-only models were assessed \\nin 74 records (5.2%).\\nIn the medical-domain LLMs (99 records), decoder-\\nonly models dominated with 79 records (79.8%). \\nEncoder-decoder models were mentioned in 4 records \\n(4.0%), and encoder-only models in 14 records (14.1%). \\nFor 2 records (2.0%), the architecture type was not explic\\xad\\nitly detailed.\\nAmong the 1,340 decoder-only general-domain LLMs, \\nChatGPT was the most frequently evaluated, with 242 \\nrecords (18.1%), followed by ChatGPT-4 (175 records, \\n13.1%), GPT-4 (165 records, 12.3%), and ChatGPT-3.5 \\n(139 records, 10.4%). Google PaLM 2/Bard/Gemini was \\nassessed in 118 records (8.8%), while GPT-3.5 appeared \\nTable 1\\u2002 Key questions for data extraction\\nQ1\\nBased on the article provided, which medical field does \\nthis article pertain to?\\nQ2\\nIs the language of the article a non-English language? \\n(yes\\u2009=\\u20091, No\\u2009=\\u20090)\\nQ3\\nIs an LLM or GPT mentioned in the article used for educa\\xad\\ntional purposes in medical/clinical field? (yes\\u2009=\\u20091, No\\u2009=\\u20090)\\nQ4\\nIs an LLM or GPT mentioned in the article used for exami\\xad\\nnation and evaluating purposes in medical/clinical field? \\n(yes\\u2009=\\u20091, No\\u2009=\\u20090)\\nQ5\\nIs the evaluation of the LLM or GPT conducted by hu\\xad\\nmans or compared with humans? (yes\\u2009=\\u20091, No\\u2009=\\u20090)\\nQ6\\nWhat is the name of the LLM(s) or GPT(s) version evalu\\xad\\nated in the article?\\nQ7\\nWhat is the targeted group of interest for the LLM or GPT \\nmentioned in the article (e.g., doctors, nurses, students, \\npatients)?\\nQ8\\nHow are the responses of the LLM evaluated?\\nQ9\\nWhat is the gold standard against which the LLM’s \\nresponses are compared?\\nQ10\\nWhat tools, scales, or set of questions are used in the \\nevaluation, and how many questions are there?\\nQ11\\nWhat parameters are assessed to measure the LLM’s \\nresponses?\\nPage 4 of 11\\nShool et al. BMC Medical Informatics and Decision Making          (2025) 25:117 \\nin 58 records (4.3%). Other models included Meta Llama \\n2 (46 records, 3.4%), Microsoft Copilot/Bing (44 records, \\n3.3%), Meta Llama 3 (41 records, 3.1%), and Anthropic \\nClaude (39 records, 2.9%).\\nSmaller groups of models included Mistral (27 records, \\n2.0%), Qwen (2.5-72b) (20 records, 1.5%), GPT-3.5 Turbo \\n(19 records, 1.4%), GPT-4o (14 records, 1.0%), ChatGPT-\\n4o and Mixtral (each with 11 records, 0.8%), and Llama \\nFig. 1\\u2002 PRISMA flow diagram for systematic reviews which included searches of databases\\n \\nPage 5 of 11\\nShool et al. BMC Medical Informatics and Decision Making          (2025) 25:117 \\n(10 records, 0.7%). Models such as Baichuan (9 records, \\n0.7%), Perplexity AI (8 records, 0.6%), GPT models, \\nVicuna, PMC-LLaMA, and Gemma (each with 7 records, \\n0.5%) followed.\\nA variety of models were evaluated in fewer than six \\nrecords, such as GPT-4 Turbo, InternLM, ChatGPT (cus\\xad\\ntomized), GPT-4o mini, and GPT-2, all with five records \\n(0.4%). Models like GPT-3, ChatGPT3.5-turbo, ERNIE \\nBot, and ChatGPT-3 were each assessed in four records \\n(0.3%). Numerous other models, including Yi-C, OpenAI \\no1-mini, ChatGPT+, and WizardLM, were evaluated in \\nthree records (0.2%).\\nThe remaining models, including OpenAI o1-preview, \\nFalcon, InstructGPT, and others, were assessed in two \\nor fewer records (0.1%), with many—such as Baize-\\nHealthcare, Alpaca, and DanteLLM_instruct_7b-v0.2-\\nboosted—evaluated only once.\\nAmong the 21 general-domain encoder-decoder LLMs, \\nChatGLM was the most frequently evaluated, appear\\xad\\ning in 9 records (42.9%). Both Flan-T5 and GLM-4 were \\neach evaluated in 4 records (19.0%), while BART was \\nassessed in 3 records (14.3%). FLAN-UL2 was evaluated \\nin 1 record (4.8%).\\nAmong the 74 encoder-only general-domain LLMs, \\nBERT was the most frequently evaluated, appearing in \\n34 records (45.9%), followed by RoBERTa in 9 records \\n(12.2%) and BioBERT in 7 records (9.5%). SciBERT and \\nALBERT were each assessed in 3 records (4.1%). AfroX\\xad\\nLMR and M-BERT were evaluated in 2 records each \\n(2.7%).\\nSeveral models were evaluated only once (1.4%), \\nincluding AfriBERTa-large, AfroLM-active-l, Camem\\xad\\nBERT-with-Dates, KoBERT, ELECTRA, DNA-BERT, \\nCH-BERT, \\nAlphaBERT, \\nSentenceBERT, \\nDistilBERT, \\nDeBERTa, ColBERT, and CliRoberta (domain-adaptive \\npre-trained LLM).\\nAmong the 79 decoder-only medical-domain LLMs, \\nthe most frequently evaluated were Meditron and Huatu\\xad\\noGPT, each appearing in 10 records (12.7%). BioMistral \\nfollowed with 6 records (7.6%), while BioGPT was evalu\\xad\\nated in 5 records (6.3%). PULSE, MedAlpaca, and Ascle\\xad\\npius were each assessed in 4 records (5.1%).\\nOther models included MMed-Llama, which was eval\\xad\\nuated in 3 records (3.8%), and several models, including \\nDocOA, ChatMed, BianQue, BenTsao, and BioMedLM, \\neach assessed in 2 records (2.5%).\\nThe remaining models, such as SenseNova, Collec\\xad\\ntiveSFT-7B, Clinical Camel (70B), GutGPT, Doctor \\nPuJiang (Dr. PJ), ChatDoctor, AntGLM-Med-10, MedL\\xad\\nlama2, MedGPT-7B, MedicalGPT, EyeGPT (fine-tuned \\nversion of Llama2), Drug-GPT, DermGPT, Aeyeconsult \\n(based on GPT-4), MedLM Medium, MedPaLM, Med42 \\n(based on Llama-2), HyperCLOVA X, Hermes7b_ITA \\n(Nous-Hermes-llama-2-7b), EthioLLM-large, EthioLLM, \\nACS-GPT, and DrBode models, were each evaluated in 1 \\nrecord (1.3%).\\nAmong the 4 encoder-decoder medical-domain LLMs, \\nall were evaluated in a single record (25.0% each). These \\nincluded MOPH (a Chinese-specific ophthalmic LLM), \\nBiomedNLP, CLINGEN (a knowledge-infused LLM \\nmodel), and Clinical-T5-Large.\\nAmong the 14 encoder-only medical-domain LLMs, \\nGatorTron and BioClinicalBERT were the most fre\\xad\\nquently evaluated, each appearing in 3 records (21.4%). \\nThe remaining models, including MoLFormer-XL (Pro\\xad\\ntein-specific LLMs), CancerBERT, MentalBERT, Clini\\xad\\ncalBERT, BioMed-RoBERTa, and BioALBERT, were each \\nevaluated in 1 record (7.1%).\\nAmong the medical-domain LLMs with architecture \\nnot explicitly detailed, two models were evaluated, each \\nappearing in 1 record (50.0%). These included LICT \\n(Large language model-based Identifier for Cell Types) \\nand ClinicLLM (an LLM trained on [HOSPITAL]’s clini\\xad\\ncal notes).\\nMajor specialties evaluated\\nIn total, the studies analyzed 781 records, providing a \\ncomprehensive overview of the distribution of medical \\nspecialties in this research. Surgery was the most fre\\xad\\nquently evaluated specialty, accounting for 220 records \\n(28.2%). Within surgery, ophthalmology was the most \\ncommon subspecialty, with 55 records (25.0%), followed \\nby orthopedics with 44 records (20.0%), and urology and \\notolaryngology each with 31 records (14.1%). Plastic sur\\xad\\ngery accounted for 20 records (9.1%), while general sur\\xad\\ngery was represented in 12 records (5.5%). Less common \\nsubspecialties included obstetrics and gynecology with 6 \\nrecords (2.7%), neurosurgery and bariatric surgery with 5 \\nrecords each (2.3%), hand surgery with 3 records (1.4%), \\nvascular, laparoscopic, and spine surgery each with 2 \\nrecords (0.9%), and trauma and thoracic surgery each \\nwith 1 record (0.5%).\\nInternal medicine was the second most frequently eval\\xad\\nuated specialty, with 119 records (15.2%). Within internal \\nmedicine, oncology was the predominant subspecialty, \\naccounting for 56 records (47.1%), followed by endocri\\xad\\nnology with 22 records (18.5%), gastroenterology and \\nhepatology with 18 records (15.1%), rheumatology with 8 \\nrecords (6.7%), nephrology with 6 records (5.0%), hema\\xad\\ntology with 5 records (4.2%), pulmonology with 3 records \\n(2.5%), and general internal medicine with 1 record \\n(0.8%).\\nMedical informatics was the third most commonly \\nevaluated specialty, with 112 records (14.3%), followed \\nby radiology with 64 records (8.2%) and general medicine \\nwith 53 records (6.8%). Medical education was assessed \\nin 52 records (6.7%), while neurology was evaluated in 40 \\nrecords (5.1%), and psychiatry in 30 records (3.8%).\\nPage 6 of 11\\nShool et al. BMC Medical Informatics and Decision Making          (2025) 25:117 \\nEmergency medicine was represented in 21 records \\n(2.7%), cardiology in 15 records (1.9%), dermatology in \\n11 records (1.4%), and pediatrics in 10 records (1.3%). \\nPathology accounted for 7 records (0.9%), radiation \\noncology for 5 records (0.6%), and infectious diseases and \\nanesthesiology each for 4 records (0.5%). Nuclear medi\\xad\\ncine and geriatrics each accounted for 3 records (0.4%), \\nand family medicine and sports medicine each for 2 \\nrecords (0.3%). Finally, chronic diseases, patient educa\\xad\\ntion, physical medicine and rehabilitation (physiatry), \\nand sleep medicine were each evaluated in 1 record \\n(0.1%).\\nTarget audience for LLMs evaluation\\nThe Target audience for LLMs evaluation includes a \\ntotal of 976 instances, distributed across various tar\\xad\\ngeted groups of interest. Doctors constitute the largest \\ngroup, with 306 instances (31.4%), followed by patients, \\naccounting for 260 instances (26.6%). Medical and \\nhealthcare professionals and researchers make up sig\\xad\\nnificant portions, with 100 instances (10.2%) and 98 \\ninstances (10.0%), respectively.\\nStudents and residents together represent 103 \\ninstances, with students contributing 72 instances (7.4%) \\nand residents 31 instances (3.2%). Smaller groups include \\nhealthcare providers at 19 instances (1.9%), caregiv\\xad\\ners with 10 instances (1.0%), nurses and general people \\neach with 7 instances (0.7%), and families or parents of \\npatients contributing 13 instances (1.3%). Educators (6 \\ninstances, 0.6%) and learners (3 instances, 0.3%) are the \\nleast represented categories.\\nLastly, 44 instances (4.5%) fall under the “others or not \\nmentioned” category, representing data that does not \\npertain to the primary groups of interest.\\nGrouping and evaluation criteria for LLM studies\\nThe studies were categorized into various groups based \\non specific criteria. as follows:\\n\\u2009\\t•\\nGroup A-e: Studies where the language assessed was \\nexclusively English, as determined by the answer to \\nQ2.\\n\\u2009\\t•\\nGroup A-ne: Studies where the languages assessed \\nincluded non-English languages or languages other \\nthan English, as determined by the answer to Q2.\\n\\u2009\\t•\\nGroup B-h: Studies where evaluations were \\nconducted directly by humans or compared with \\nhuman evaluations (e.g., experts or others), as \\ndetermined by the positive answer to Q5.\\n\\u2009\\t•\\nGroup B-nh: Studies where evaluations were not \\nconducted directly by humans or were not compared \\nwith human evaluations, as determined by the \\nnegative answer to Q5.\\n\\u2009\\t•\\nGroup C: Studies where LLMs were explicitly used \\nfor educational purposes in the medical or clinical \\nfield, as determined by the positive answer to Q3.\\n\\u2009\\t•\\nGroup D: Studies where LLMs were specifically \\nused for examination and evaluation purposes in \\nthe medical or clinical field, as determined by the \\npositive answer to Q4.\\nThis categorization highlights the diverse applications \\nand evaluation contexts of LLMs in medical research, \\ndemonstrating the various ways these models are inte\\xad\\ngrated and assessed within the field.\\nEvaluation parameters\\nA comprehensive analysis of evaluation parameters \\nacross the 761 studies, as summarized in Table S2 (col\\xad\\numn Q11), revealed 2,239 instances of parameter usage. \\nAfter filtering for parameters that appeared in more than \\n1% of the total instances, 16 parameters were identi\\xad\\nfied as the most frequently evaluated. These parameters, \\nrecorded verbatim from the studies, reflect the diverse \\napproaches used to assess large language models (LLMs) \\nin various contexts, particularly in the medical and clini\\xad\\ncal fields.\\nFigure\\xa02 presents the percentage distribution of these \\nparameters, both across the total dataset and within \\nspecific study groups, highlighting variations in focus \\ndepending on the application or evaluation criteria.\\n1.\\t Accuracy was the most commonly assessed \\nparameter, appearing in 419 instances, representing \\n21.78% of evaluations in Group A-e, 22.99% in Group \\nA-ne, 21.64% in Group B-h, 21.84% in Group B-nh, \\n20.38% in Group C, and 24.31% in Group D.\\n2.\\t Consistency was evaluated in 33 instances (2.19% \\nin Group A-e, 2.20% in Group A-ne, 1.46% in Group \\nB-h, 2.15% in Group B-nh, 2.23% in Group C, and \\n3.45% in Group D).\\n3.\\t Performance was recorded in 34 instances, with \\nnotable percentages in Group A-ne (6.95%), Group \\nB-h (4.68%), and Group D (5.17%), compared to \\n1.95% in Group A-e, 1.99% in Group B-nh, and 2.65% \\nin Group C.\\n4.\\t Reliability was assessed in 46 instances, with \\nrelatively higher percentages in Group B-nh (2.70%) \\nand Group C (2.97%) compared to other groups.\\n5.\\t Clarity was evaluated in 35 instances but remained \\nless prominent in most groups (<\\u20091.0% in Group B-h \\nand Group D), with slightly higher percentages in \\nGroup B-nh (2.10%) and Group C (2.44%).\\n6.\\t Quality was reported in 43 instances, with its \\nhighest percentage in Group C (3.82%) and modest \\nlevels in Group A-e (2.88%) and Group B-nh (2.76%).\\nPage 7 of 11\\nShool et al. BMC Medical Informatics and Decision Making          (2025) 25:117 \\n7.\\t Readability was a major focus, evaluated in 95 \\ninstances, showing significant emphasis in Group \\nC (6.48%) and consistent usage across Groups A-e \\n(4.29%), A-ne (4.81%), and B-h (4.68%).\\n8.\\t Reasoning appeared in 13 instances, with notable \\npercentages in Group A-ne (2.14%) and Group D \\n(2.76%), while being evaluated at <\\u20091.0% in other \\ngroups.\\n9.\\t Comprehensiveness, assessed in 47 instances, was \\nmost emphasized in Group C (3.29%) and Group \\nA-ne (3.20%), with smaller percentages in other \\ngroups.\\n10.\\tCompleteness, appearing in 49 instances, was \\nconsistently evaluated across most groups, with the \\nhighest percentage in Group B-nh (2.81%).\\n11.\\tCorrectness was recorded in 34 instances, with its \\nhighest emphasis in Group D (3.10%) and Group C \\n(2.76%).\\nFig. 2\\u2002 Distribution of evaluation parameters in total and across groups\\n \\nPage 8 of 11\\nShool et al. BMC Medical Informatics and Decision Making          (2025) 25:117 \\n12.\\tSafety was assessed in 21 instances, with small \\npercentages across all groups, peaking at 1.80% in \\nGroup C.\\n13.\\tAppropriateness appeared in 24 instances, with \\nmodest evaluation levels across groups, peaking at \\n1.65% in Group B-nh.\\n14.\\tRelevancy, reported in 43 instances, was evaluated \\nmost prominently in Group B-nh (2.43%).\\n15.\\tSensitivity, assessed in 31 instances, showed a \\nhigher focus in Group B-h (2.05%) compared to \\nother groups.\\n16.\\tSpecificity was recorded in 30 instances, with \\nmodest levels across all groups, peaking at 1.46% in \\nGroup B-h.\\nDiscussion\\nEvaluation types\\nThe assessment of large language models (LLMs) in \\nhealthcare requires advanced evaluation methodologies \\nthat prioritize context-specific metrics, safety, and accu\\xad\\nracy, surpassing traditional benchmarks. These method\\xad\\nologies must also address critical concerns such as data \\nprivacy, ethical implications, and risks posed by inac\\xad\\ncuracies or biases. Additionally, the unique demands of \\nhealthcare require LLMs to interpret and generate spe\\xad\\ncialized medical content with high reliability and contex\\xad\\ntual relevance \\u200b [6, 7].\\nThis study highlights a dramatic increase in research \\ninterest in LLMs in healthcare, with publications surging \\nfrom a single study in 2019 to 557 in 2024. This exponen\\xad\\ntial growth underscores the expanding capabilities and \\nclinical potential of LLMs, particularly in diagnostics, \\ndecision support, medical education, and patient com\\xad\\nmunication. However, the lack of standardized evaluation \\ntools, variability in study designs, and ethical concerns \\nsuch as data privacy and hallucination risks represent key \\nbarriers to effective evaluation of LLMs in clinical set\\xad\\ntings. Addressing these issues requires interdisciplinary \\nefforts and the development of robust frameworks tai\\xad\\nlored to clinical contexts\\u200b \\u200b [8–10].\\nBarriers\\nClinical evaluations of LLMs necessitate interdisci\\xad\\nplinary collaboration to meet the intricate demands \\nof medical practice, requiring rigorous validation and \\noptimization for diverse clinical applications. The grow\\xad\\ning use in healthcare underscores the urgent need for \\nstandardized evaluation frameworks to assess their per\\xad\\nformance and safety effectively \\u200b [11–13]. While LLMs \\noffer significant advancements, their rapid development \\nraises ethical concerns, including the potential erosion \\nof human expertise, reduced interpersonal interactions, \\nand risks of misuse. For instance, AI-generated medi\\xad\\ncal advice could diminish the role of human empathy \\nin patient care. Ensuring responsible development and \\ndeployment through regulatory oversight is critical to \\nmitigate these risks and balance innovation with societal \\nwell-being.\\nFrameworks\\nWhile no single evaluation framework has been univer\\xad\\nsally adopted, several studies propose initial guidelines, \\nemphasizing metrics such as transparency, explainabil\\xad\\nity, and clinical relevance. These frameworks could serve \\nas a foundation for future systematic evaluations. Our \\nanalysis of 761 studies provides a comprehensive over\\xad\\nview of the evaluation parameters and applications of \\nLLMs in healthcare. The studies focused predominantly \\non general-domain LLMs (93.55%), with decoder-only \\narchitectures like ChatGPT and GPT-4 being the most \\nfrequently evaluated models. Medical-domain LLMs, \\naccounting for 6.45% of studies, demonstrated early but \\npromising specialization, with models such as Meditron \\nand HuatuoGPT being the most assessed. However, the \\nlimited evaluation of encoder-decoder and encoder-only \\nmodels, both in general and medical domains, reveals a \\ngap in exploring alternative architectures. Its extensive \\nuse in clinical settings underscores its versatility and \\nsuperior performance in diagnostics and generating dif\\xad\\nferential diagnoses, reflecting its enhanced linguistic and \\ncontextual processing capabilities [14–16].\\nApplications and trends\\nThe analysis underscores the evaluation of a wide array \\nof LLMs, with around one thirds of studies focusing on \\nGPT models like GPT-4, and specialized or customized \\nvariants, reflecting tailored explorations for specific clini\\xad\\ncal tasks. Other models, including Google Bard, Micro\\xad\\nsoft Bing, and BERT variants, along with Claude, Llama, \\nand PaLM2, are also reviewed, pointing to a vibrant AI \\nresearch landscape in healthcare. Yet, the limited assess\\xad\\nment of these models highlights the necessity for stan\\xad\\ndardized evaluation frameworks to enable effective \\ncomparisons \\u200b [17].\\u200b.\\nThe evaluation of LLMs in healthcare reveals sig\\xad\\nnificant variations in research focus and application, \\nunderscoring the critical need to align research priori\\xad\\nties with clinical demands. Surgery emerged as the most \\nfrequently evaluated specialty, representing 28.2% of all \\nstudies, reflecting its prominent role in healthcare. How\\xad\\never, critical specialties such as cardiology (1.9%) and \\nemergency medicine (2.7%) remain significantly under\\xad\\nrepresented despite their global importance. These find\\xad\\nings highlight the necessity for future research to target \\nhigh-burden and underserved areas to maximize the \\npotential impact of LLMs in clinical practice.\\nPage 9 of 11\\nShool et al. BMC Medical Informatics and Decision Making          (2025) 25:117 \\nSubspecialty analysis\\nThe analysis of subspecialties within surgery emphasizes \\nthe dominance of ophthalmology (25.0%), orthopedics \\n(20.0%), and urology and otolaryngology (14.1% each). \\nDespite their importance, general surgery (5.5%) and \\nother subspecialties, including neurosurgery and vascu\\xad\\nlar surgery, were evaluated far less frequently, highlight\\xad\\ning potential gaps in research coverage. Similarly, internal \\nmedicine—a key specialty—was the second most evalu\\xad\\nated area (15.2%), with oncology (47.1%) leading among \\nits subspecialties. However, other critical areas, such as \\nnephrology (5.0%) and pulmonology (2.5%), were mini\\xad\\nmally represented, signaling the need for broader evalua\\xad\\ntions within this domain. Future research should focus on \\naligning LLM evaluations with the specific clinical needs \\nof diverse medical specialties to ensure their effective and \\nresponsible integration into healthcare practice [4, 6].\\nParameter evaluations\\nA total of 2,239 parameter evaluations were identified, \\nwith accuracy emerging as the most frequently assessed \\nmetric (419 instances, 21.78%). This reflects the critical \\nimportance of producing precise and reliable outputs in \\nclinical settings. Other frequently evaluated parameters, \\nsuch as readability (95 instances, 4.29%) and reliabil\\xad\\nity (46 instances, 2.53%), emphasize the need for out\\xad\\nputs that are both clear and dependable. Less commonly \\nassessed parameters, including safety, bias, and appropri\\xad\\nateness, highlight areas requiring more focused research \\nto address potential risks and ethical challenges in clini\\xad\\ncal applications.\\nOur grouping framework, based on language, applica\\xad\\ntion purposes, and evaluation methods, revealed distinct \\npatterns in LLM usage and assessment:\\nGroup A-e and Group A-ne studies collectively empha\\xad\\nsized accuracy as a key evaluation parameter, with usage \\nrates of 21.78% and 22.99%, respectively. This reflects the \\ncritical need for precise and dependable outputs, regard\\xad\\nless of whether the language focus was exclusively Eng\\xad\\nlish or included non-English languages. Group A-ne \\nstudies, which included non-English languages, showed \\na higher focus on performance (6.95%) and comprehen\\xad\\nsiveness (3.20%), reflecting the challenges of evaluating \\nmultilingual capabilities.\\nGroup B-h, involving direct human evaluations, \\nemphasized accuracy (21.64%) and correctness (1.80%), \\nhighlighting the role of expert validation in ensuring the \\nclinical utility of LLM outputs.\\nGroup B-nh, which relied on automated or indi\\xad\\nrect evaluations, focused on metrics like completeness \\n(2.81%) and quality (2.76%), reflecting the need for reli\\xad\\nable outputs in contexts without human oversight.\\nGroup \\nC, \\naddressing \\neducational \\napplications, \\nplaced significant emphasis on readability (6.48%) and \\ncomprehensiveness (3.29%), crucial for effective knowl\\xad\\nedge dissemination.\\nGroup D, targeting examination and evaluation pur\\xad\\nposes, highlighted accuracy (24.31%) and correctness \\n(3.10%) as key metrics, underscoring the importance of \\ndependable outputs in high-stakes contexts.\\nThese group-specific analyses provide valuable insights \\ninto how LLMs are assessed across diverse research con\\xad\\ntexts, reflecting the tailored objectives and priorities of \\neach group. Notably, the limited focus on ethical param\\xad\\neters like safety and bias across all groups highlights a \\ncritical gap that must be addressed to ensure equitable \\nand responsible LLM integration.\\nLimitations\\nThe evaluation of LLMs in healthcare highlights their \\nvaried applications and categorization by language and \\nmethods. Nonetheless, several issues persist, includ\\xad\\ning an excessive focus on accuracy, which does not ade\\xad\\nquately capture the complexity of model performance in \\nclinical settings. Essential factors like safety, fairness, and \\nbias are often neglected, and many studies rely on closed-\\nended tasks, failing to mirror the complexity of clinical \\ndecision-making which requires comprehensive, open-\\nended reasoning \\u200b [8, 18].\\nAdditionally, the categorization of studies by language \\nand purpose reveals varied applications of LLMs and \\nunderscores a lack of standardized evaluation practices. \\nThis fragmentation impedes a unified understanding of \\nLLMs’ capabilities across medical fields. Moreover, the \\napplication of LLMs in clinical settings faces challenges, \\nas the lack of domain-specific training data can cause \\ninaccuracies, especially in precise fields like radiology or \\ngenetics \\u200b [6, 19].\\nA notable limitation of this study is the restriction of \\nthe search strategy to titles of published studies. This \\napproach, while providing a focused scope, may have \\nexcluded relevant studies identifiable through abstracts. \\nFuture systematic reviews in this domain should consider \\nexpanding the search strategy to include both titles and \\nabstracts to ensure a more comprehensive capture of eli\\xad\\ngible studies.\\nThe lack of standardized definitions for some evalua\\xad\\ntion parameters and the variability in human evaluation \\npractices are recognized as limitations of this review. \\nWhile this work identifies trends in parameter usage \\nand grouping criteria, future research should explore \\nstandardizing these definitions and frameworks within \\nspecific medical specialties or model types. Some find\\xad\\nings, such as the distribution of clinical specialties and \\ntarget audiences, provide contextual insights but are not \\ndirectly aligned with the primary focus on evaluation \\nmethods. Future reviews could streamline the analysis to \\nalign more closely with evaluation frameworks.\\nPage 10 of 11\\nShool et al. BMC Medical Informatics and Decision Making          (2025) 25:117 \\nFuture directions and perspectives\\nTo fully realize the potential of large language models \\n(LLMs) in healthcare, future efforts should prioritize sev\\xad\\neral key areas. First, enhancing interpretability is criti\\xad\\ncal to developing transparent models that clinicians can \\ntrust for reliable decision support. Establishing robust \\nvalidation frameworks tailored to the complexities of \\nclinical settings is equally essential to ensure the accu\\xad\\nracy and applicability of LLM outputs. Ethical consider\\xad\\nations, such as safeguarding data privacy, mitigating bias, \\nand addressing the societal impacts of automation, must \\nalso be a primary focus. Additionally, the evolving roles \\nof healthcare professionals require exploration, as these \\ntechnologies may shift their responsibilities from deci\\xad\\nsion-makers to supervisors of AI-generated insights. To \\nmitigate risks associated with misuse or overreliance on \\nLLMs, the development of comprehensive governance \\nframeworks is imperative, ensuring their deployment \\naligns with ethical and safety standards. Finally, address\\xad\\ning barriers to adoption, including resource constraints \\nand resistance to change, will require interdisciplinary \\ncollaboration and targeted education efforts to foster \\nacceptance and successful integration into healthcare \\npractices.\\nConclusions\\nThis systematic review underscores the expanding role of \\nLLMs in clinical medicine, highlighting their potential to \\nrevolutionize medical diagnostics, education, and patient \\ncare. While their applications are diverse, critical chal\\xad\\nlenges remain, including the need for standardized evalu\\xad\\nation frameworks, attention to ethical considerations, \\nand the underrepresentation of high-priority medical \\nspecialties. Addressing these challenges through inter\\xad\\ndisciplinary collaboration and robust governance will \\nbe essential for the responsible deployment of LLMs. \\nFuture research should focus on enhancing model inter\\xad\\npretability, tailoring evaluations to clinical complexities, \\nand addressing disparities in specialty-specific applica\\xad\\ntions. By aligning technological advancements with clini\\xad\\ncal needs, LLMs can drive significant improvements in \\nhealthcare outcomes.\\nAbbreviations\\nLLM\\t\\n\\x07Large Language Model\\nSupplementary Information\\nThe online version contains supplementary material available at \\u200bh\\u200bt\\u200bt\\u200bp\\u200bs\\u200b:\\u200b/\\u200b/\\u200bd\\u200bo\\u200bi\\u200b.\\u200bo\\u200br\\u200b\\ng\\u200b/\\u200b1\\u200b0\\u200b.\\u200b1\\u200b1\\u200b8\\u200b6\\u200b/\\u200bs\\u200b1\\u200b2\\u200b9\\u200b1\\u200b1\\u200b-\\u200b0\\u200b2\\u200b5\\u200b-\\u200b0\\u200b2\\u200b9\\u200b5\\u200b4\\u200b-\\u200b4.\\nSupplementary Material 1\\nAcknowledgements\\nNot applicable.\\nAuthor contributions\\nSS, EB, and MT conceptualized the study, developed the methodology, \\nand conducted the initial literature review. SS and RSA were responsible \\nfor data extraction, analysis, and synthesis of the findings. EB, SA, and RG \\ncontributed to the interpretation of the results and provided critical revisions \\nto the manuscript. MT supervised the project, provided expert guidance on \\nthe clinical applications of LLMs, and contributed to the final review of the \\nmanuscript. All authors read and approved the final manuscript.\\nFunding\\nThis research received no specific grant from any funding agency in the \\npublic, commercial, or not-for-profit sectors.\\nData availability\\nAll data generated or analyzed during this study are included in this published \\narticle and its supplementary files.\\nDeclarations\\nEthics approval and consent to participate\\nNot applicable.\\nConsent for publication\\nNot applicable.\\nCompeting interests\\nThe authors declare no competing interests.\\nReceived: 30 September 2024 / Accepted: 26 February 2025\\nReferences\\n1.\\t\\nZhou H, Liu F, Gu B, Zou X, Huang J, Wu J et al. A survey of large language \\nmodels in medicine: progress, application, and challenge. ArXiv Preprint. \\n2023;arXiv:231105112.\\n2.\\t\\nCascella M, Montomoli J, Bellini V, Bignami E. Evaluating the feasibility of \\nChatGPT in healthcare: an analysis of multiple clinical and research scenarios. \\nJ Med Syst. 2023;47(1):33.\\n3.\\t\\nTustumi F, Andreollo NA, Aguilar-Nascimento, JEd. Future of the language \\nmodels in healthcare: the role of chatGPT. ABCD arquivos brasileiros de \\ncirurgia digestiva (são paulo). 2023;36:e1727.\\n4.\\t\\nWilhelm TI, Roos J, Kaczmarczyk R. Large language models for therapy recom\\xad\\nmendations across 3 clinical specialties: comparative study. J Med Internet \\nRes. 2023;25:e49324.\\n5.\\t\\nLahat A, Klang E. Can advanced technologies help address the global \\nincrease in demand for specialized medical care and improve telehealth \\nservices? J Telemed Telecare. 2024;30(9).\\n6.\\t\\nChen X, Xiang J, Lu S, Liu Y, He M, Shi D. Evaluating large language models in \\nmedical applications: a survey. ArXiv Preprint. 2024;arXiv:240507468.\\n7.\\t\\nKarabacak M, Margetis K. Embracing large language models for medical \\napplications: opportunities and challenges. Cureus. 2023;15(5):e39305.\\n8.\\t\\nNazi ZA, Peng W. Large language models in healthcare and medical domain: \\nA review. ArXiv Preprint. 2023;arXiv:240106775.\\n9.\\t\\nRíos-Hoyo A, Shan NL, Li A, Pearson AT, Pusztai L, Howard FM. Evaluation of \\nlarge language models as a diagnostic aid for complex medical cases. Front \\nMed. 2024;11:1380148.\\n10.\\t Zhou H, Liu F, Gu B, Zou X, Huang J, Wu J et al. A survey of large language \\nmodels in medicine: principles, applications, and challenges. arXiv preprint. \\n2023;arXiv:231105112.\\n11.\\t Busch F, Hoffmann L, Rueger C, van Dijk EHC, Kader R, Ortiz-Prado E et al. \\nSystematic review of large language models for patient care: current applica\\xad\\ntions and challenges. medRxiv. 2024:2024.03.04.24303733.\\n12.\\t Park Y-J, Pillai A, Deng J, Guo E, Gupta M, Paget M, et al. Assessing the research \\nlandscape and clinical utility of large language models: a scoping review. \\nBMC Med Inf Decis Mak. 2024;24(1):72.\\n13.\\t Perlis RH, Fihn SD. Evaluating the application of large language models in \\nclinical research contexts. JAMA Netw Open. 2023;6(10):e2335924–e.\\nPage 11 of 11\\nShool et al. BMC Medical Informatics and Decision Making          (2025) 25:117 \\n14.\\t Hoppe JM, Auer MK, Strüven A, Massberg S, Stremmel C. ChatGPT with GPT-4 \\noutperforms emergency department physicians in diagnostic accuracy: \\nretrospective analysis. J Med Internet Res. 2024;26:e56110.\\n15.\\t Mackey BP, Garabet R, Maule L, Tadesse A, Cross J, Weingarten M. Evaluating \\nChatGPT-4 in medical education: an assessment of subject exam perfor\\xad\\nmance reveals limitations in clinical curriculum support for students. Discover \\nArtif Intell. 2024;4(1):38.\\n16.\\t Ueda D, Walston SL, Matsumoto T, Deguchi R, Tatekawa H, Miki Y. Evaluating \\nGPT-4-based ChatGPT’s clinical potential on the NEJM quiz. BMC Digit Health. \\n2024;2(1):4.\\n17.\\t Alessandri-Bonetti MGR, Naegeli M, Liu HY, Egro FM. Assessing the soft tissue \\ninfection expertise of ChatGPT and Bard compared to IDSA recommenda\\xad\\ntions. Ann Biomed Eng. 2023.\\n18.\\t Liu F, Zhou H, Hua Y, Rohanian O, Clifton L, Clifton DA. Large lan\\xad\\nguage models in healthcare: A comprehensive benchmark. MedRxiv. \\n2024:2024.04.24.24306315.\\n19.\\t García-Méndez S, de Arriba-Pérez F. Large language models and healthcare \\nalliance: potential and challenges of two representative use cases. Ann \\nBiomed Eng. 2024;52(8):1928–31.\\nPublisher’s note\\nSpringer Nature remains neutral with regard to jurisdictional claims in \\npublished maps and institutional affiliations.\\n'}]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "massages_for(text, 'Turkish')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a851aa55-30e6-440d-ba08-0cc7b316b121",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize(text, language):\n",
    "    response = openai.chat.completions.create(\n",
    "        model = 'gpt-4o-mini',\n",
    "        messages = massages_for(text, language)\n",
    "    )\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1b012e68-5d96-4a05-b062-eabfb2548213",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"**Özet**\\n\\n**Arka Plan:** Büyük Diller Modelleri (LLM'ler), dönüştürücü mimariler üzerine inşa edilen gelişmiş yapay zeka araçlarıdır ve klinik tıpta karar verme desteği, tanı ve tıbbi eğitim gibi alanlarda önemli potansiyellere sahiptir. Ancak, klinik iş akışlarına entegrasyonları için güvenilirlik, güvenlik ve etik uyum açısından titiz bir değerlendirme gereklidir.\\n\\n**Amaç:** Bu sistematik inceleme, klinik tıpta LLM'ler hakkında yapılan değerlendirme parametrelerini ve metodolojileri inceleyerek yeteneklerini, sınırlamalarını ve uygulama trendlerini vurgular.\\n\\n**Yöntem:** PubMed, Scopus, Web of Science, IEEE Xplore ve arXiv veri tabanlarında kapsamlı bir literatür taraması gerçekleştirildi. Önceden belirlenen dahil etme ve hariç tutma kriterlerine göre, tıbbi bağlamlarda LLM performansını değerlendiren özgün araştırmalar belirlendi. \\n\\n**Sonuçlar:** Tarama sonucunda 761 çalışma seçilmiş olup, genel alan LLM'leri (özellikle ChatGPT ve GPT-4) %93.55 oranla, tıbbi alan LLM'leri ise yalnızca %6.45 oranla yer almaktadır. En sık değerlendirilen parametre kesinlik olup (%21.78) belirlenmiştir. Ancak, mevcut kanıt tabanı bazı sınırlamalar ve önyargılar göstermekte, bu nedenle dikkatli bir yorum ve sağlam değerlendirme çerçevelerinin gerekliliği vurgulanmaktadır.\\n\\n**Sonuçlar:** LLM'ler üzerindeki araştırmaların hızlı yükselişi, sağlık hizmetlerinde dönüşüm potansiyelini ortaya koymaktadır. Yine de etik riskler, değerlendirme değişkenliği ve kritik uzmanlıkların yeterince temsil edilmemesi gibi zorlukların üstesinden gelinmesi gerekmektedir. Gelecek çalışmalar, klinik pratiğe güvenli, etkili ve eşit bir entegrasyon sağlamak için standartlaştırılmış çerçevelere odaklanmalıdır.\\n\\n**Anahtar Kelimeler:** Sistematik inceleme, büyük dil modelleri, LLM değerlendirmesi, klinik tıp, tıpta yapay zeka, sağlıkta derin öğrenme, doğal dil işleme. \\n\\nBu çalışma, LLM'lerin klinik tıptaki potansiyelinin yanı sıra, karşılaşılan zorlukları keşfederek, gelecekteki araştırmaların odaklandığı alanları belirlemektedir. Bu, LLM'lerin sağlık uygulamalarında daha geniş bir benimsenmesi için gereken standartları belirlemeye yönelik bir adımdır.\""
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summarize(text, 'Turkish')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e19d7bea-2756-4be5-8f82-b2cd3445d930",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_summary(text, language):\n",
    "    summary = summarize(text, language)\n",
    "    display(Markdown(summary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0934ae41-a623-4dc0-86e7-3c5fa3a73568",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**Büyük Dil Modellerinin Klinik Tıptaki Değerlendirmeleri Üzerine Sistematik İnceleme**\n",
       "\n",
       "**Özeti:**\n",
       "Bu sistematik inceleme çalışması, Klinik Tıp'ta büyük dil modellerinin (LLM) değerlendirilmesine yönelik parametreler ve metodolojileri incelemektedir. Bu modellerin (örneğin ChatGPT, GPT-4) klinik karar destek sistemlerinde, tanılarda ve tıbbi eğitimdeki potansiyeli vurgulanırken, güvenilirlik, güvenlik ve etik uygunluk konularının titiz değerlendirmelere tabi tutulması gerektiği belirtilmektedir.\n",
       "\n",
       "**Araştırma Amacı:**\n",
       "LLM'lerin sağlık alanındaki değerlendirme yöntemlerini ve uygulama alanlarını belirlemek amacıyla yapılan bu çalışmada, 761 ilgili çalışma incelenmiştir. Araştırma, genel alan LLM'lerinin (özellikle ChatGPT ve GPT-4) değerlendirmelerde baskın olduğunu, ancak tıbbi alanda kullanılan LLM'lerin oldukça az olduğunu göstermektedir.\n",
       "\n",
       "**Metodoloji:**\n",
       "Literatür incelemesi, PubMed, Scopus, Web of Science, IEEE Xplore ve arXiv gibi veritabanları üzerinden gerçekleştirilmiştir. Seçilen çalışmalar, önceden tanımlanmış kriterlere göre süzgeçten geçirilmiş ve yalnızca orijinal araştırmalar dahil edilmiştir.\n",
       "\n",
       "**Ana Bulgular:**\n",
       "- Eğlence veya genel alan LLM'leri üzerine yapılan çalışmalar 761 pozitif sonuçla belirlenmiştir.\n",
       "- Doğruluk, en yaygın değerlendirme parametresi olmuştur.\n",
       "- LLM'ler arasında en çok değerlendirilen yapı, genel alan LLM'leri ile özellikle decoders-only modeller olmuştur.\n",
       "- Klinik uygulamalarda bazı önemli uzmanlık alanlarının yeterince temsil edilmediği görülmektedir.\n",
       "  \n",
       "**Sonuçlar:**\n",
       "LLM'lerin klinik tıptaki rolleri hızla artmaktadır, ancak eğitim ve güvenlik konularındaki zorluklar aşılmalıdır. Gelecek çalışmaların standartlaştırılmış değerlendirme çerçevelerine odaklanması ve kritik uzmanlık alanlarına yönelmesi gerektiği belirtilmektedir. \n",
       "\n",
       "**Anahtar Kelimeler:**\n",
       "Büyük dil modelleri, LLM değerlendirmesi, Klinik tıp, Yapay zeka, Tıbbi eğitim."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_summary(text, 'Turkish')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f706742d-589a-495e-b092-108cbfaf4dc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "The document is a systematic review that investigates the evaluation of Large Language Models (LLMs) in clinical medicine. It highlights both the burgeoning interest in LLMs for enhancing decision support, diagnostics, and medical education, as well as the need for rigorous assessments to ensure their safety, reliability, and ethical use.\n",
       "\n",
       "### Purpose\n",
       "The primary objective of this review is to examine the evaluation parameters and methodologies used for assessing LLMs in healthcare settings. It aims to summarize the capabilities, limitations, and trends in the application of these models in clinical contexts.\n",
       "\n",
       "### Methods\n",
       "The review encompasses literature from various databases (PubMed, Scopus, Web of Science, IEEE Xplore, and arXiv) and includes both peer-reviewed and preprint studies. The researchers applied strict inclusion and exclusion criteria to identify 761 original research articles pertinent to the evaluations of LLMs in medical contexts.\n",
       "\n",
       "### Key Findings\n",
       "1. **Growth in Research**: There is a notable increase in studies focused on LLMs, rising dramatically from a mere 1 publication in 2019 to 557 in 2024, signifying growing interest and utility in healthcare.\n",
       "\n",
       "2. **Model Types**: The majority of the evaluated models (93.55%) were general-domain LLMs such as ChatGPT and GPT-4, while only 6.45% pertained to medical-domain LLMs. Among medical models, decoder-only architectures were the most common.\n",
       "\n",
       "3. **Evaluation Metrics**: The most frequently assessed parameter was accuracy, appearing in 21.78% of the evaluations. Other parameters like consistency, performance, and clarity were also noted but were less emphasized.\n",
       "\n",
       "4. **Specialty Representation**: Surgical specialties were the most frequently evaluated (28.2% of studies), particularly ophthalmology and orthopedics. Critical specialties such as cardiology and emergency medicine were notably underrepresented.\n",
       "\n",
       "5. **Target Audience**: The targeted evaluations primarily included doctors (31.4%), followed by patients (26.6%). The studies showed a diverse range of applications and audiences, including educational uses and examination purposes in medicine.\n",
       "\n",
       "### Conclusions\n",
       "The review emphasizes the transformative potential of LLMs in healthcare but also points out significant challenges, such as variability in evaluation methods, the need for standardized frameworks, and ethical concerns surrounding bias and data privacy. Addressing these issues is crucial for the responsible integration of LLMs into clinical practice. The authors recommend future research to focus on model interpretability and developing guidelines that align LLM assessments with specific clinical needs.\n",
       "\n",
       "Overall, while LLMs show promise in revolutionizing healthcare, careful and ethical evaluation frameworks must accompany their advancement to maximize benefits in medical practice."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_summary(text, 'English')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a5c0881-6baf-4b8e-aa2e-9df06d055826",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "I finished this project. I used two languages in this project. The results may differ from each other because we send a summary request to the AI model for each summary preparation. <br>\n",
    "I am improving myself on LLM models and I will prepare the same project. I am new to this field. I may have made mistakes. I am sorry about that. \n",
    "I hope my project was useful for you. Thank you for taking a look at my project. I will continue to share projects. If you want to be informed in advance,  you can follow me from the links below.\n",
    "\n",
    "[LinkedIn](https://www.linkedin.com/in/ihsancenkiz/)\n",
    "[GitHub](https://github.com/ihsncnkz)\n",
    "[Kaggle](https://www.kaggle.com/ihsncnkz)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
